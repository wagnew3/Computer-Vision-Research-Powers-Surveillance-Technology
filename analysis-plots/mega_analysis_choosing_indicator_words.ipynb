{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "205c9b24-5635-4a03-9e6a-a808d85215ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths to your data\n",
    "from pathlib import Path\n",
    "data_dir = str(Path('').parent / 'analysis')\n",
    "paper_info_filename = 'cvpr_paper_info_and_keywords.pkl'\n",
    "paper_extra_info_filename = 'cvpr_papers_to_all_patents'\n",
    "codes_filename = 'codes_keywords_filtered.txt'\n",
    "countries_filename = 'country-codes.txt'\n",
    "elite_univs_filename = 'elite_universities.txt'\n",
    "\n",
    "codes_of_interest = ['surveil', 'hard_crime',\n",
    "                     'body_parts', 'bodies',\n",
    "                     'demographic', 'children',\n",
    "                     'scenes', \n",
    "                     #'significant_traces', \n",
    "                     'hard_movement', 'soft_influence', \n",
    "                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e0513-004c-4ca1-836f-c294989a1a66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d0877b8-64c6-4ab1-b0b5-8ad82164ccd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Imports'''\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "from itertools import chain\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pickle\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio; pio.renderers.default = \"iframe\"\n",
    "from os.path import join\n",
    "from IPython.display import display\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "np.random.seed(1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abd0ccbc-f072-420a-a5ec-cbec2118704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Make output directories if necessary'''\n",
    "(figs_dir := Path(data_dir) / '..' / 'figures').mkdir(exist_ok=True)\n",
    "(patent_dir := Path(data_dir) / 'patents').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19fff160-b892-4a1b-9309-17bc747b55c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Helpers to handle paper and patent data'''\n",
    "def read_lists(filename, filter_comments=True):\n",
    "    '''Read a file containing codes in our special format and return a dictionary of the codes'''\n",
    "    with open(filename) as f:\n",
    "        d = {section.split('\\n')[0].strip('## '): [item for item in section.strip().split('\\n')[1:] if item]  # code to keywords\n",
    "             for section in f.read().split('\\n\\n')}  # for each code's section\n",
    "    if filter_comments:\n",
    "        d = {key: [item.split('#')[0].strip() for item in d[key] if not item.startswith('#')] for key in d}  # keep real part of valid lines\n",
    "        for key in list(d):\n",
    "            if d[key] == []:  # delete codes with no items\n",
    "                del d[key]\n",
    "    return d\n",
    "\n",
    "def write_lists(lists, filename):\n",
    "    '''Write a file containing codes in our special format.'''\n",
    "    split = '\\n'\n",
    "    s = \"\\n\\n\".join([f'## {header}\\n{split.join([item for item in lists[header]])}' for header in lists])\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(s)\n",
    "    \n",
    "def load_papers():\n",
    "    '''Load all papers and info into a Pandas DataFrame'''\n",
    "    papers = (pd.read_pickle(os.path.join(data_dir, paper_info_filename))\n",
    "              .rename_axis('PaperId')  # Rename index\n",
    "              .rename(dict(DisplayName='Institution', DisplayName_fields='Field'), axis=1))  # Rename some columns\n",
    "    # Load papers' patents\n",
    "    papers_patents = pickle.load(open(os.path.join(data_dir, paper_extra_info_filename), 'rb'))\n",
    "    papers_patents = DataFrame(papers_patents.items(), columns=['PaperId',  'patents']).set_index('PaperId')  # Convert to Dataframe\n",
    "    papers_patents.patents = papers_patents.patents.apply(lambda patents: [p.replace('-', '') for p in patents])\n",
    "    # Combine and clean\n",
    "    papers = papers.join(papers_patents)\n",
    "    papers.patents = papers.patents.fillna(\"\").apply(list)\n",
    "    for col in ['PaperId', 'Latitude', 'Longitude']:  # Clean columns that say the same info multiple times\n",
    "        papers[col] = papers[col].apply(lambda vals: vals[0])\n",
    "    papers.Year = papers.Year.astype(int)  # Convert year column from strings to integers\n",
    "    papers['Decade'] = papers.Year.apply(lambda year: 10 * (year//10))  # Save decade\n",
    "    # Aggregate keyword columns into code columns\n",
    "    codes = read_lists(join(data_dir, codes_filename))\n",
    "    missing_keywords = [keyword for keyword in sum(codes.values(), []) if keyword not in papers.columns]\n",
    "    if missing_keywords:\n",
    "        print(f'No data on these keywords so they will be ignored:\\n{\", \".join(missing_keywords)}')\n",
    "    for code, keywords in codes.items():\n",
    "        papers[f'{code}_code'] = papers[[keyword for keyword in keywords if keyword in papers.columns]].sum(axis=1)\n",
    "    # Add whether a paper was ever cited in a patent (either of the following two lines have the same result)\n",
    "    papers['n_patents'] = papers.patents.apply(len)\n",
    "    # papers['n_patents'] = papers['keyword_depth_vec'].apply(lambda cites: int(cites[0,:,0].sum()))\n",
    "    return papers\n",
    "\n",
    "def filter_paper_years(papers, year_range=range(1990, 2022), years_to_drop=[1990, 1995, 2002]):\n",
    "    '''Filter papers DataFrame to requested years and return updated Pandas DataFrame. The defaults result in limiting to the years we view as reliable data.'''\n",
    "    return papers.query('(Year in @year_range) & (Year not in @years_to_drop)')\n",
    "    \n",
    "def mark_interesting(papers, codes_of_interest):\n",
    "    '''Given papers DataFrame and which codes are of interest (list of strings), add columns indicating which papers are of interest and related info'''\n",
    "    papers['patents_of_interest'] = papers[codes_of_interest].sum(axis=1).apply(set).apply(list)\n",
    "    papers['n_patents_of_interest'] = papers.patents_of_interest.apply(len)\n",
    "    papers['n_patents_not_of_interest'] = papers.n_patents - papers.n_patents_of_interest\n",
    "\n",
    "def analyze_sources(papers, source):\n",
    "    '''Given papers DataFrame and desired source type for analysis (string, e.g. Institution, Country, Field, Year, or Decade), collect and return institutions DataFrame'''\n",
    "    # Each link between a source and a paper+details (e.g. a paper affiliated with U.S. and China has two otherwise identical rows)\n",
    "    if source == 'Country':  # Extra step before\n",
    "        source = 'Iso3166Code'\n",
    "    links = (papers[[source, 'PaperId', 'patents', 'n_patents', 'patents_of_interest', 'n_patents_of_interest']]\n",
    "             .explode(source)  # each paper has multiple links\n",
    "             .drop_duplicates(['PaperId', source])  # remove duplicate links\n",
    "             .reset_index(drop=True))\n",
    "    if source == 'Iso3166Code':  # Extra step after\n",
    "        source = 'Country'\n",
    "        countries = dict([line.strip().split('\\t') for line in open(os.path.join(data_dir, countries_filename)).readlines()])\n",
    "        links.insert(0, 'Country', links.Iso3166Code.replace(countries))\n",
    "    # Summarize the sources' downstream patents\n",
    "    sources_general_info = links.groupby(source).agg(dict(PaperId=list, patents=sum)).rename(dict(PaperId='papers'), axis=1)\n",
    "    sources_general_info.patents = sources_general_info.patents.apply(set).apply(list)  # drop duplicate patents\n",
    "    sources_patent_info = links.query('n_patents > 0').groupby(source).agg(dict(PaperId=list)).rename(dict(PaperId='papers_patented'), axis=1)\n",
    "    sources_info_of_interest = links.query('n_patents_of_interest > 0').groupby(source).agg(dict(PaperId=list, patents_of_interest=sum)).rename(dict(PaperId='papers_of_interest'), axis=1)\n",
    "    sources_info_of_interest.patents_of_interest = sources_info_of_interest.patents_of_interest.apply(set).apply(list)  # drop duplicate patents\n",
    "    sources = sources_general_info.join([sources_patent_info, sources_info_of_interest]).reset_index()\n",
    "    for col in ['papers', 'papers_patented', 'patents', 'papers_of_interest', 'patents_of_interest']:\n",
    "        sources[col] = sources[col].fillna(\"\").apply(list)\n",
    "        sources[f'n_{col}'] = sources[col].apply(len)\n",
    "    # Drop generic sources\n",
    "    if source == 'Field':\n",
    "        generic_fields = [\n",
    "            'Artificial intelligence', 'Computer vision', 'Pattern recognition', 'Mathematics', 'Computer science', \n",
    "            'Machine learning', 'Deep learning', 'Algorithm', '(', 'Convolutional neural net', 'Pixel', 'Artificial neural networks']\n",
    "        sources = sources[~sources.Field.apply(lambda field: any([generic_field.lower() in field.lower() for generic_field in generic_fields]))]\n",
    "    # Clean\n",
    "    sources = sources.replace('French Institute for Research in Computer Science and Automation', 'IRIA')\n",
    "    sources = sources.replace('Korea Advanced Institute of Science and Technology', 'Korea Advanced Inst. of Science & Tech.')\n",
    "    sources = sources.replace('University of Illinois Urbana-Champaign', 'Urbana-Champaign')\n",
    "    sources = sources.replace('University of California, Berkeley', 'Berkeley')\n",
    "    sources = sources.replace('Massachusetts Institute of Technology', 'MIT')\n",
    "    sources = sources.replace('Cognitive neuroscience of visual object recognition', 'CogSci of object recognition')\n",
    "    if source == 'Institution':\n",
    "        sources.Institution = sources.Institution.apply(lambda name: name.replace('University', 'Univ.'))\n",
    "    if source == 'Decade':\n",
    "        decades_of_interest = [1990, 2010]\n",
    "        sources = sources.query('Decade in @decades_of_interest')\n",
    "    return sources\n",
    "\n",
    "def filter_lists(lists_fp, constraint, flag):\n",
    "    '''Add a note to list items that do not satisfy the constraint'''\n",
    "    old_lists = read_lists(lists_fp, filter_comments=False)\n",
    "    lists = {header: [item if (item.startswith('#') or constraint(item)) else f'# {item}  # {flag}' for item in old_lists[header]] \n",
    "             for header in old_lists}\n",
    "    write_lists(lists, lists_fp)\n",
    "    return read_lists(lists_fp)\n",
    "\n",
    "def code_name(code):\n",
    "    return f'{code}_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f298d838-57e8-4467-98c5-c2784c2a6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load papers and codes'''\n",
    "papers = filter_paper_years(load_papers())\n",
    "codes = read_lists(join(data_dir, codes_filename))\n",
    "keywords_of_interest = sum([codes[code] for code in codes_of_interest], [])\n",
    "write_lists({'final': keywords_of_interest}, join(data_dir, 'final_keywords.txt'))\n",
    "mark_interesting(papers, [code_name(code) for code in codes_of_interest])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8093b514-1c71-4993-8c87-3d311e1839ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Drop certain keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "383b66d7-f75f-4eda-858f-0695e4dc4830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note keywords that were not searched for during automatic annotation of our largescale dataset\n",
    "constraint = lambda keyword: keyword in all_papers.columns\n",
    "codes = filter_lists(join(data_dir, codes_filename), constraint, 'not assessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c1e7ed4-91de-4230-9e54-dc04742ca103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note which keywords never occur\n",
    "constraint = lambda keyword: len(all_papers[keyword].sum()) > 10\n",
    "codes = filter_lists(join(data_dir, codes_filename), constraint, 'does not occur')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2b7d3e-9817-4d92-9b96-488a10f29a0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Pull example sentences for manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6ba5d046-98f1-4e83-a99d-7bfd7b789e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''Helpers for getting keywords' example patents and example sentences'''\n",
    "def get_patent_url(patent):\n",
    "    return f\"https://patents.google.com/patent/{patent}/en\"\n",
    "def get_patent_soup_fresh(patent):\n",
    "    page = requests.get(get_patent_url(patent))  # get page from online\n",
    "    return BeautifulSoup(page.content, \"html.parser\")\n",
    "def get_patent_soup(patent, patent_dir):\n",
    "    path = os.path.join(patent_dir, f'{patent}.pkl')\n",
    "    if not os.path.exists(path):  # download\n",
    "        pickle.dump(get_patent_soup_fresh(patent), open(path, 'wb'))\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "def get_patent_title(patent, patent_dir):\n",
    "    return get_patent_soup(patent, patent_dir).find('span', dict(itemprop=\"title\")).get_text().strip()\n",
    "def get_patent_main(patent, patent_dir):\n",
    "    soup = get_patent_soup(patent, patent_dir)\n",
    "    divs = soup.find_all('div', {'class': 'description-paragraph'})\n",
    "    return '\\n\\n'.join(map(str,divs))\n",
    "def find_example_div(patent, s, patent_dir):\n",
    "    div_start, div_end = '<div[^>]*>', '</div>'\n",
    "    return re.search(f'{div_start}(.* {s} .*){div_end}', get_patent_main(patent, patent_dir), flags=re.I).groups()[0]\n",
    "def find_example_sentence(text, keyword):\n",
    "    non_stops = ['(\\. \\d)*', '(\\.\\d)*', '(\\..\\.)*']  # periods that are not stops, e.g., decimals, abbreviations, ...\n",
    "    return re.search(f'([^.]*{\"\".join(non_stops)}[^.]* {keyword} [^.]*\\.)', text, flags=re.I).groups()[0]\n",
    "\n",
    "# Unit tests:\n",
    "# patent, keyword = 'WO2014005022A1', 'apartment'  # Set these\n",
    "# print(f'patents.google.com/patent/{patent}/en')\n",
    "# get_patent_soup(patent, patent_dir)\n",
    "# get_patent_main(patent, patent_dir)\n",
    "# div = find_example_div(patent, keyword, patent_dir)\n",
    "# sentence = find_example_sentence(div, keyword)\n",
    "# get_patent_title(patent, patent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dae7186e-f739-49c2-827f-40b5fc9d5aba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " iris\n",
      "US8050463 Iris recognition system having image quality metrics \n",
      "US10289908 Method, apparatus, and computer program product for tracking eye gaze and eye movement \n",
      "US8761458 System for iris detection, tracking and recognition at a distance \n",
      "CN104735361A Method and apparatus for acquiring a set of images illuminated by a flash \n",
      "US9504420 Methods and arrangements for identifying dermatological diagnoses with clinically negligible probabilities \n",
      " irises\n",
      "US10580133 Techniques for identifying blepharoptosis from an image \n",
      "EP1764758A1 Lane boundary recognition apparatus for vehicle  - failed \n",
      "US10311768 Virtual window \n",
      "US9965982 Near-eye light field display \n",
      "US10275648 Image processing method and system for iris recognition \n",
      " face\n",
      "US9836641 Generating numeric embeddings of images \n",
      "US10134440 Video summarization using audio and visual cues \n",
      "US10223621 Artificially intelligent systems, devices, and methods for learning and/or using visual surrounding for autonomous object operation \n",
      "US9460462 Monetization using video-based simulation of cosmetic products \n",
      "CN102667763A Facial recognition with social network aiding \n",
      " facial\n",
      "US10134440 Video summarization using audio and visual cues \n",
      "US10438055 Human facial detection and recognition system \n",
      "US9275269 System, method and apparatus for facial recognition \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US10007986 Linear-based eulerian motion modulation \n",
      " gesture\n",
      "CN103886585A Video tracking method based on rank learning \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US9201580 Sound alignment user interface \n",
      "US9349039 Gesture recognition device and control method for the same \n",
      "US9052746 User center-of-mass and mass distribution extraction using depth images \n",
      " torso\n",
      "WO2019052917A1 Subject identification systems and methods \n",
      "US10165230 Systems and methods for configuring baby monitor cameras to provide uniform data sets for analysis and to provide an advantageous view point of babies \n",
      "US10169647 Inferring body position in a scan \n",
      "US10395411 Skinned multi-person linear model \n",
      "US9672417 Scale independent tracking pattern \n",
      " anatomy\n",
      "WO2016081994A1 Gait monitoring system, method and device \n",
      "US9858475 Method and system of hand segmentation and overlay using depth data \n",
      "US10169647 Inferring body position in a scan \n",
      "US10002419 Direct computation of image-derived biomarkers \n",
      "US10733745 Methods, systems, and computer readable media for deriving a three-dimensional (3D) textured surface from endoscopic video \n",
      " anatomies\n",
      "US10482606 Medical image reporting system and method \n",
      "US10524866 Systems and methods for registration of location sensors \n",
      "US9179888 System and method for providing patient registration without fiducials \n",
      "US9033887 Mitral valve detection for transthoracic echocardiography \n",
      "US9582891 Method and apparatus for segmenting an image in order to locate a part thereof \n",
      " joint\n",
      "EP3096292A1 Multi-object tracking with generic object proposals  - failed \n",
      "WO2020049385A1 Multi-view image clustering techniques using binary compression \n",
      "CN103544483B A kind of joint objective method for tracing based on local rarefaction representation and system thereof  - failed \n",
      "US10395411 Skinned multi-person linear model \n",
      "US10269169 Three-dimensional motion capture \n",
      " limb\n",
      "WO2016081994A1 Gait monitoring system, method and device \n",
      "US9232912 System for evaluating infant movement using gesture recognition \n",
      "US9052746 User center-of-mass and mass distribution extraction using depth images \n",
      "US10395411 Skinned multi-person linear model \n",
      "US9046962 Methods, systems, apparatuses, circuits and associated computer executable code for detecting motion, position and/or orientation of objects within a defined spatial region \n",
      " hand\n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US10130308 Calculating respiratory parameters from thermal measurements \n",
      "US9349039 Gesture recognition device and control method for the same \n",
      "US9052746 User center-of-mass and mass distribution extraction using depth images \n",
      "US9393487 Method for mapping movements of a hand-held controller to game commands \n",
      " finger\n",
      "US9349039 Gesture recognition device and control method for the same \n",
      "US9046962 Methods, systems, apparatuses, circuits and associated computer executable code for detecting motion, position and/or orientation of objects within a defined spatial region \n",
      "US9412003 Discriminant function specifying device, discriminant function specifying method, and biometric identification device \n",
      "US10163215 Object learning and recognition method and system \n",
      "US9684171 See-through computer display systems \n",
      " person\n",
      "US10134440 Video summarization using audio and visual cues \n",
      "ES2452790A1 Procedure and image analysis system (Machine-translation by Google Translate, not legally binding)  - failed \n",
      "EP2805306B1 Method and device for generating a motion field for a video sequence  - failed \n",
      "US10223621 Artificially intelligent systems, devices, and methods for learning and/or using visual surrounding for autonomous object operation \n",
      "US9460462 Monetization using video-based simulation of cosmetic products \n",
      " people\n",
      "US10134440 Video summarization using audio and visual cues \n",
      "ES2452790A1 Procedure and image analysis system (Machine-translation by Google Translate, not legally binding)  - failed \n",
      "CN105389784A Image processing method and terminal \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US10130308 Calculating respiratory parameters from thermal measurements \n",
      " track\n",
      "US10134440 Video summarization using audio and visual cues \n",
      "CN103886585A Video tracking method based on rank learning \n",
      "EP2805306B1 Method and device for generating a motion field for a video sequence  - failed \n",
      "US10068344 Method and system for 3D capture based on structure from motion with simplified pose detection \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      " human\n",
      "US10223621 Artificially intelligent systems, devices, and methods for learning and/or using visual surrounding for autonomous object operation \n",
      "US9052746 User center-of-mass and mass distribution extraction using depth images \n",
      "CN108596856A A kind of image defogging method and device  - failed \n",
      "CN102667763A Facial recognition with social network aiding \n",
      "EP1235182A2 Motion picture generation from a static digital image  - failed \n",
      " pedestrian\n",
      "CN108124095B Image processing method and image system for vehicle  - failed \n",
      "CN106228560A A kind of demographic method under complex scene  - failed \n",
      "EP3058510B1 A method for producing a histogram of oriented gradients  - failed \n",
      "US9875579 Techniques for enhanced accurate pose estimation  - failed \n",
      "CN104731324B A kind of gesture inner plane rotation detection model generation method based on HOG+SVM frameworks  - failed \n",
      " foot traffic\n",
      "US9213781 System and method for processing image data  - failed \n",
      "US10545500 Model for determining drop-off spot at delivery location \n",
      "US10410048 System and method for detecting, tracking and counting human objects of interest using a counting system and a data capture device \n",
      "US10878294 Mobile cleaning robot artificial intelligence for situational awareness \n",
      "US10733427 System and method for detecting, tracking, and counting human objects of interest using a counting system and a data capture device \n",
      " room\n",
      "EP3401815A1 Determining an architectural layout  - failed \n",
      "US8479225 Social and interactive applications for mass media \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US9436963 Visualizing a custom product in situ \n",
      "US9412003 Discriminant function specifying device, discriminant function specifying method, and biometric identification device \n",
      " scene\n",
      "US10134440 Video summarization using audio and visual cues \n",
      "ES2452790A1 Procedure and image analysis system (Machine-translation by Google Translate, not legally binding)  - failed \n",
      "EP2805306B1 Method and device for generating a motion field for a video sequence  - failed \n",
      "US9052746 User center-of-mass and mass distribution extraction using depth images \n",
      "CN104951791B data classification method and device \n",
      " office\n",
      "CN106228560A A kind of demographic method under complex scene  - failed \n",
      "US9324144 Device having a digital infrared sensor and non-touch optical detection of vital signs from a temporal variation amplifier \n",
      "US9426536 Systems, methods and computer readable media for instant multi-channel video content browsing in digital video distribution systems \n",
      "CN106022228B A kind of three-dimensional face identification method based on grid local binary patterns in length and breadth  - failed \n",
      "US10380506 Generation of occupant activities based on recorded occupant behavior \n",
      " store\n",
      "US9836641 Generating numeric embeddings of images \n",
      "US10134440 Video summarization using audio and visual cues \n",
      "ES2452790A1 Procedure and image analysis system (Machine-translation by Google Translate, not legally binding)  - failed \n",
      "EP2805306B1 Method and device for generating a motion field for a video sequence  - failed \n",
      "US8493401 Image processing apparatus, image displaying apparatus, and image processing method \n",
      " street\n",
      "US9437044 Method and system for displaying and navigating building facades in a three-dimensional mapping system \n",
      "US10467526 Artificial intelligence system for image similarity analysis using optimized image pair selection and multi-scale convolutional neural networks \n",
      "EP3096292A1 Multi-object tracking with generic object proposals  - failed \n",
      "US10223621 Artificially intelligent systems, devices, and methods for learning and/or using visual surrounding for autonomous object operation \n",
      "US9342930 Information aggregation for recognized locations \n",
      " crowd\n",
      "EP3096292A1 Multi-object tracking with generic object proposals  - failed \n",
      "WO2019052917A1 Subject identification systems and methods \n",
      "US9504420 Methods and arrangements for identifying dermatological diagnoses with clinically negligible probabilities \n",
      "CN108537818A Crowd's trajectory predictions method based on cluster pressure LSTM  - failed \n",
      "CN102667763A Facial recognition with social network aiding \n",
      " home\n",
      "US9275269 System, method and apparatus for facial recognition \n",
      "CN103886585A Video tracking method based on rank learning \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US10223621 Artificially intelligent systems, devices, and methods for learning and/or using visual surrounding for autonomous object operation \n",
      "US9052746 User center-of-mass and mass distribution extraction using depth images \n",
      " house\n",
      "US9275269 System, method and apparatus for facial recognition \n",
      "US9076065 Detecting objects in images \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US10558323 Systems and methods for smart home automation using a multifunction status and entry point icon \n",
      "US9442929 Determining documents that match a query \n",
      " apartment\n",
      "CN104820718B Image classification and search method based on geographic location feature Yu overall Vision feature \n",
      "WO2013174867A1 Method for modeling a building or a room of same on the basis of a limited number of photographs of the walls thereof  - failed \n",
      "US9110470 Systems and methods for using multiple hypotheses in a visual simultaneous localization and mapping system \n",
      "US10558323 Systems and methods for smart home automation using a multifunction status and entry point icon \n",
      "US9354794 Method and system for performing client-side zooming of a remote video feed \n",
      " airport\n",
      "WO2016025189A1 Multi-layer aggregation for object detection \n",
      "US9483689 Biometric matching technology \n",
      "US10474899 Social engagement based on image resemblance \n",
      "US10358234 Systems and methods of capturing large area images in detail including cascaded cameras and/or calibration features \n",
      "US9239957 Image processing method and apparatus \n",
      " location\n",
      "US9836641 Generating numeric embeddings of images \n",
      "EP2805306B1 Method and device for generating a motion field for a video sequence  - failed \n",
      "US10223621 Artificially intelligent systems, devices, and methods for learning and/or using visual surrounding for autonomous object operation \n",
      "US9052746 User center-of-mass and mass distribution extraction using depth images \n",
      "US7956889 Video surveillance system \n",
      " geolocation\n",
      "US9275269 System, method and apparatus for facial recognition \n",
      "US10618673 Systems and methods for dynamic planning and operation of autonomous systems using image observation and information theory \n",
      "US10488198 Surveying system \n",
      "US9504420 Methods and arrangements for identifying dermatological diagnoses with clinically negligible probabilities \n",
      "US9984582 Peered proctoring \n",
      " GPS\n",
      "US9275269 System, method and apparatus for facial recognition  - failed \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US10130308 Calculating respiratory parameters from thermal measurements \n",
      "US10223621 Artificially intelligent systems, devices, and methods for learning and/or using visual surrounding for autonomous object operation \n",
      "US9235821 Methods, apparatus, and systems for providing an enhanced positive response for underground facility locate and marking operations based on an electronic manifest documenting physical locate marks on ground, pavement or other surface \n",
      " friend\n",
      "US10165230 Systems and methods for configuring baby monitor cameras to provide uniform data sets for analysis and to provide an advantageous view point of babies \n",
      "US10216761 Generating congruous metadata for multimedia \n",
      "US10805533 Wide area imaging system and method \n",
      "CN102667763A Facial recognition with social network aiding \n",
      "US9467834 Mobile device emergency service \n",
      " social network\n",
      "US9275269 System, method and apparatus for facial recognition \n",
      "US9076065 Detecting objects in images \n",
      "US10558323 Systems and methods for smart home automation using a multifunction status and entry point icon \n",
      "US10165230 Systems and methods for configuring baby monitor cameras to provide uniform data sets for analysis and to provide an advantageous view point of babies \n",
      "US9504420 Methods and arrangements for identifying dermatological diagnoses with clinically negligible probabilities \n",
      " family\n",
      "US9275269 System, method and apparatus for facial recognition \n",
      "CN106228560A A kind of demographic method under complex scene  - failed \n",
      "WO2019025925A1 Method and apparatus for encoding or decoding video content including regions having looping videos of different loop lengths  - failed \n",
      "US9437044 Method and system for displaying and navigating building facades in a three-dimensional mapping system \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      " preference\n",
      "US8144957 Medical image data processing and feature identification system \n",
      "US9324144 Device having a digital infrared sensor and non-touch optical detection of vital signs from a temporal variation amplifier \n",
      "US10713534 Training a learning based defect classifier \n",
      "US9875579 Techniques for enhanced accurate pose estimation \n",
      "US9349039 Gesture recognition device and control method for the same \n",
      " personalize\n",
      "US9324144 Device having a digital infrared sensor and non-touch optical detection of vital signs from a temporal variation amplifier \n",
      "US10169647 Inferring body position in a scan \n",
      "US10740660 Item recommendations based on image feature data \n",
      "US9636018 Hand-held medical-data capture-device having a digital infrared sensor with no analog readout ports and optical detection of vital signs through variation amplification and interoperation with electronic medical record systems \n",
      "US10114460 Virtual reality sensory construct \n",
      " recommend\n",
      "WO2016081994A1 Gait monitoring system, method and device \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US10130308 Calculating respiratory parameters from thermal measurements \n",
      "CN106845513A Staff detector and method based on condition random forest  - failed \n",
      "CN103299324B Potential son is used to mark the mark learnt for video annotation \n",
      " preference\n",
      "US8144957 Medical image data processing and feature identification system \n",
      "US9324144 Device having a digital infrared sensor and non-touch optical detection of vital signs from a temporal variation amplifier \n",
      "US10713534 Training a learning based defect classifier \n",
      "US9875579 Techniques for enhanced accurate pose estimation \n",
      "US9349039 Gesture recognition device and control method for the same \n",
      " targeting\n",
      "US9317930 Systems and methods for statistics collection using pixel mask  - failed \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US9858475 Method and system of hand segmentation and overlay using depth data \n",
      "US10558323 Systems and methods for smart home automation using a multifunction status and entry point icon \n",
      "US9046962 Methods, systems, apparatuses, circuits and associated computer executable code for detecting motion, position and/or orientation of objects within a defined spatial region \n",
      " advertisement\n",
      "US9275269 System, method and apparatus for facial recognition \n",
      "WO2013054839A1 Knowledge information processing server system provided with image recognition system  - failed \n",
      "US10558323 Systems and methods for smart home automation using a multifunction status and entry point icon \n",
      "US10740660 Item recommendations based on image feature data \n",
      "US9460462 Monetization using video-based simulation of cosmetic products \n",
      " purchase\n",
      "US10740660 Item recommendations based on image feature data \n",
      "US9460462 Monetization using video-based simulation of cosmetic products \n",
      "CN102667763A Facial recognition with social network aiding \n",
      "US10699453 Digital media environment for style-aware patching in a digital image \n",
      "WO2019207176A1 Modelling of nonlinear soft-tissue dynamics for interactive avatars  - failed \n",
      " travel\n",
      "US9275269 System, method and apparatus for facial recognition \n",
      "US9393487 Method for mapping movements of a hand-held controller to game commands \n",
      "US9467834 Mobile device emergency service \n",
      "US10012505 Wearable system for providing walking directions \n",
      "CN103426165A Precise registration method of ground laser-point clouds and unmanned aerial vehicle image reconstruction point clouds  - failed \n",
      " border\n",
      "CN105389784A Image processing method and terminal \n",
      "US9046962 Methods, systems, apparatuses, circuits and associated computer executable code for detecting motion, position and/or orientation of objects within a defined spatial region \n",
      "CN105046701B A kind of multiple dimensioned well-marked target detection method based on patterned lines  - failed \n",
      "CN102667763A Facial recognition with social network aiding \n",
      "US9436963 Visualizing a custom product in situ \n",
      " license plate\n",
      "US8533204 Text-based searching of image data \n",
      "US10627820 Controller systems and methods of limiting the operation of neural networks to be within one or more conditions \n",
      "US9904850 Fast recognition algorithm processing, systems and methods \n",
      "US9355123 \n",
      "CN107305634A A kind of license plate locating method returned based on integrated random fern and shape  - failed \n",
      "US10542248 Hierarchical binary structured light patterns \n",
      " airport\n",
      "WO2016025189A1 Multi-layer aggregation for object detection \n",
      "US9483689 Biometric matching technology \n",
      "US10474899 Social engagement based on image resemblance \n",
      "US10358234 Systems and methods of capturing large area images in detail including cascaded cameras and/or calibration features \n",
      "US9239957 Image processing method and apparatus \n",
      " baggage\n",
      "US9095287 System and method for iris data acquisition for biometric identification \n",
      "US10296791 Mobile identity platform \n",
      "US10853757 Video for real-time confirmation in package tracking systems \n",
      "US10572963 Detection of items \n",
      "US9996890 \n",
      "WO2019070442A1 Image processing for person recognition  - failed \n",
      " criminal\n",
      "US9483689 Biometric matching technology \n",
      "US10248664 Zero-shot sketch-based image retrieval techniques using neural networks for sketch-image recognition and retrieval \n",
      "US10579860 Learning model for salient facial region detection \n",
      "US9239957 Image processing method and apparatus \n",
      "US9076042 Method of generating index elements of objects in images captured by a camera system \n",
      " crime\n",
      "US10545500 Model for determining drop-off spot at delivery location \n",
      "US9483689 Biometric matching technology \n",
      "CN106056079A Image acquisition device and facial feature occlusion detection method  - failed \n",
      "CN102214359B Target tracking device and method based on hierarchic type feature matching \n",
      "US9091536 Method and device for three-dimensional surface detection with a dynamic reference frame \n",
      " prisoner\n",
      "US10437884 Navigation of computer-navigable physical feature graph \n",
      "US10321094 Secure video visitation system \n",
      "CN103020655A Remote identity authentication method based on single training sample face recognition \n",
      "US10296994 System and method for visitation management in a controlled environment \n",
      "US10853901 \n",
      "US9060714 System for detection of body motion \n",
      " prison\n",
      "CN106108932B Full-automatic kidney region of interest extraction element and method  - failed \n",
      "CN107066922A The target tracking method monitored for land resources  - failed \n",
      "CN108062574A A kind of Weakly supervised object detection method based on particular category space constraint  - failed \n",
      "CN105590099B A kind of more people's Activity recognition methods based on improvement convolutional neural networks  - failed \n",
      "US10437884 Navigation of computer-navigable physical feature graph \n",
      " fraud\n",
      "US10032140 Systems for recycling consumer electronic devices \n",
      "EP3640814A1 User-friendly explanation production using generative adversarial networks  - failed \n",
      "FR3086884A1 METHOD FOR DETECTION OF DOCUMENTARY FRAUD.  - failed \n",
      "US9076042 Method of generating index elements of objects in images captured by a camera system \n",
      "US9292630 Methods and systems for capturing the condition of a physical structure via audio-based 3D scanning \n",
      " security\n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US9235821 Methods, apparatus, and systems for providing an enhanced positive response for underground facility locate and marking operations based on an electronic manifest documenting physical locate marks on ground, pavement or other surface \n",
      "US10783268 Data allocation based on secure information retrieval \n",
      "US9830681 Multi-dimensional model dimensioning and scale error correction \n",
      "US9412003 Discriminant function specifying device, discriminant function specifying method, and biometric identification device \n",
      " defense\n",
      "US8947592 Handheld imaging device with image processor provided with multiple parallel processing units \n",
      "US10839556 Camera pose estimation using obfuscated features \n",
      "US9373174 Cloud based video detection and tracking system \n",
      "US9075977 System for using spoken utterances to provide access to authorized humans and automated agents \n",
      "US9692939 Device, system, and method of blind deblurring and blind super-resolution utilizing internal patch recurrence \n",
      " combat\n",
      "US9787397 Self identifying modulated light source \n",
      "US9268404 Application gesture interpretation \n",
      "US10130308 Calculating respiratory parameters from thermal measurements \n",
      "US10062182 See-through computer display systems \n",
      "US9939911 Computer interface for remotely controlled objects and wearable articles with absolute pose detection component \n",
      " enemy\n",
      "US9270976 Multi-user stereoscopic 3-D panoramic vision system and method \n",
      "US10062182 See-through computer display systems \n",
      "US9939911 Computer interface for remotely controlled objects and wearable articles with absolute pose detection component \n",
      "US10698223 \n",
      "US10755390 Image deblurring method based on light streak information in an image  - failed \n",
      "US9420203 Vision system for a vehicle \n",
      " enemies\n",
      "US9875579 Techniques for enhanced accurate pose estimation \n",
      "US10404636 Embedded programs and interfaces for chat conversations \n",
      "US10348658 Suggested items for use with embedded applications in chat conversations \n",
      "US9767577 Techniques for accurate pose estimation \n",
      "US10880243 \n",
      "US9767575 Techniques for accurate pose estimation in outdoor environments \n",
      " drone\n",
      "US10839535 Systems and methods for providing depth map information \n",
      "US9213937 Apparatus and methods for gating analog and spiking signals in artificial neural networks \n",
      "US9761002 Stereo-motion method of three-dimensional (3-D) structure information extraction from a video for fusion with 3-D point cloud data \n",
      "US9940726 System and method to improve object tracking using tracking fingerprints \n",
      "US10839556 Camera pose estimation using obfuscated features \n",
      " aircraft\n",
      "US9875579 Techniques for enhanced accurate pose estimation \n",
      "US8718410 Image capture and identification system and process  - failed \n",
      "US10665115 Controlling unmanned aerial vehicles to avoid obstacle collision \n",
      "US9393487 Method for mapping movements of a hand-held controller to game commands \n",
      "EP2879090B1 Aligning ground based images and aerial imagery  - failed \n",
      " military\n",
      "US10618673 Systems and methods for dynamic planning and operation of autonomous systems using image observation and information theory \n",
      "US9875579 Techniques for enhanced accurate pose estimation \n",
      "CN104754185A Method for processing video images \n",
      "US9784973 Micro doppler presentations in head worn computing \n",
      "US10114460 Virtual reality sensory construct \n",
      " race\n",
      "US9904850 Fast recognition algorithm processing, systems and methods \n",
      "US9355123 \n",
      "US9504420 Methods and arrangements for identifying dermatological diagnoses with clinically negligible probabilities \n",
      "US8947592 Handheld imaging device with image processor provided with multiple parallel processing units \n",
      "US10572390 Methods and apparatus for loading firmware on demand \n",
      "US10546202 Proving hypotheses for a vehicle using optimal experiment design \n",
      " ethnicity\n",
      "US9747493 Face pose rectification method and apparatus \n",
      "US10339706 Method and apparatus for estimating body shape \n",
      "US9582723 Biometric matching technology \n",
      "US10489661 Medical environment monitoring system \n",
      "US10776471 Facial recognition authentication system including path parameters \n",
      " class\n",
      "US10134440 Video summarization using audio and visual cues  - failed \n",
      "CN105389784A Image processing method and terminal \n",
      "US6778701 Feature extracting device for pattern recognition \n",
      "US10130308 Calculating respiratory parameters from thermal measurements \n",
      "EP3096292A1 Multi-object tracking with generic object proposals  - failed \n",
      " gender\n",
      "US9504420 Methods and arrangements for identifying dermatological diagnoses with clinically negligible probabilities \n",
      "US10579860 Learning model for salient facial region detection \n",
      "US7711155 Method and system for enhancing three dimensional face modeling using demographic classification \n",
      "AU2013245488B2 Facial recognition with social network aiding \n",
      "US10667697 Identification of posture-related syncope using head-mounted sensors \n",
      " female\n",
      "US9342781 Signal processing systems \n",
      "US10395411 Skinned multi-person linear model \n",
      "US7711155 Method and system for enhancing three dimensional face modeling using demographic classification \n",
      "US10234545 Light source module \n",
      "US9330206 Producing a three dimensional model of an implant \n",
      " male\n",
      "US9342781 Signal processing systems \n",
      "US10130308 Calculating respiratory parameters from thermal measurements \n",
      "US9504420 Methods and arrangements for identifying dermatological diagnoses with clinically negligible probabilities \n",
      "US10579860 Learning model for salient facial region detection \n",
      "US10395411 Skinned multi-person linear model \n",
      " woman\n",
      "US9342781 Signal processing systems \n",
      "US9460518 Visual clothing retrieval \n",
      "US9190013 Image-dependent temporal slot determination for multi-state IMODs \n",
      "US10853625 Facial signature methods, systems and software \n",
      "US9405772 Actionable search results for street view visual queries \n",
      " man\n",
      "US9342781 Signal processing systems \n",
      "US9324144 Device having a digital infrared sensor and non-touch optical detection of vital signs from a temporal variation amplifier  - failed \n",
      "CN104735361A Method and apparatus for acquiring a set of images illuminated by a flash \n",
      "US10776936 Point cloud matching method \n",
      "EP1542152B1 Object detection  - failed \n",
      " sex\n",
      "WO2015078980A2 Method and system for determining the prognosis of a patient suffering from pulmonary embolism \n",
      "CN102903135B For wrinkle aged and method and apparatus that are removing aging realistic simulation  - failed \n",
      "US10121064 Systems and methods for behavior detection using 3D tracking and machine learning \n",
      "US9603711 Patient-adapted and improved articular implants, designs and related guide tools \n",
      "CN102667763A Facial recognition with social network aiding \n",
      " disability\n",
      "WO2019063416A1 Method and device for operating a driver assistance system, and driver assistance system and motor vehicle  - failed \n",
      "US9685174 Mood monitoring of bipolar disorder using speech analysis \n",
      "US10376163 Blood pressure from inward-facing head-mounted cameras \n",
      "US10832327 Methods of providing insurance savings based upon telematics and driving behavior identification \n",
      "US10849532 Computer-vision-based clinical assessment of upper extremity function \n",
      " non-binary\n",
      "EP3594903A1 Method and system for determining a 6-dof-pose of an object in space  - failed \n",
      "US9354794 Method and system for performing client-side zooming of a remote video feed \n",
      "EP3321883A1 \n",
      "US9942450 Automatic time signature-based video matching for a camera network \n",
      "US9235900 Systems and methods for estimating depth and visibility from a reference viewpoint for pixels in a set of images captured from different viewpoints  - failed \n",
      "US10878575 Foreground-aware image inpainting \n",
      " trans\n",
      "WO2019121821A1 Method and device for operating a camera-monitor system for a motor vehicle  - failed \n",
      "US9230194 Training image sampling \n",
      "WO2018051336A1 Systems and methods for generating 3d images based on fluorescent illumination  - failed \n",
      "EP3764323A1 Information processing device, information processing method, and program  - failed \n",
      "US7138371 Remodeling and glycoconjugation of peptides \n",
      " child\n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US10130308 Calculating respiratory parameters from thermal measurements \n",
      "CN106845513A Staff detector and method based on condition random forest  - failed \n",
      "US10165230 Systems and methods for configuring baby monitor cameras to provide uniform data sets for analysis and to provide an advantageous view point of babies \n",
      "US9705995 Capability monitoring in a service oriented architecture \n",
      " children\n",
      "US9232912 System for evaluating infant movement using gesture recognition \n",
      "US10165230 Systems and methods for configuring baby monitor cameras to provide uniform data sets for analysis and to provide an advantageous view point of babies \n",
      "US9705995 Capability monitoring in a service oriented architecture \n",
      "US10223621 Artificially intelligent systems, devices, and methods for learning and/or using visual surrounding for autonomous object operation \n",
      "US10579860 Learning model for salient facial region detection \n",
      " kid\n",
      "US9426451 Cooperative photography \n",
      "US10496905 Intelligent assistant with intent-based information resolution \n",
      "US9420432 Mobile devices control \n",
      "US9183560 Reality alternate \n",
      "US9554123 \n",
      "US10002337 Method for collaborative shopping \n",
      " minor\n",
      "US9317930 Systems and methods for statistics collection using pixel mask \n",
      "CN104915946A Object segmentation method based on significance and suitable for severe degraded image \n",
      "US8982061 Angular contact geometry \n",
      "US9110470 Systems and methods for using multiple hypotheses in a visual simultaneous localization and mapping system \n",
      "US10558323 Systems and methods for smart home automation using a multifunction status and entry point icon \n",
      " youth\n",
      "US9105210 Multi-node poster location \n",
      "US9317740 Demographic analysis of facial landmarks \n",
      "US9524081 Synchronizing virtual actor's performances to a speaker's voice \n",
      "US10438052 Systems and methods for facial property identification \n",
      "US10672140 Video monitoring method and video monitoring system \n",
      " age\n",
      "WO2016081994A1 Gait monitoring system, method and device \n",
      "US9355123 Fast recognition algorithm processing, systems and methods \n",
      "US9232912 System for evaluating infant movement using gesture recognition \n",
      "US10165230 Systems and methods for configuring baby monitor cameras to provide uniform data sets for analysis and to provide an advantageous view point of babies \n",
      "US9504420 Methods and arrangements for identifying dermatological diagnoses with clinically negligible probabilities \n",
      " reidentification\n",
      "USRE46310 Ergonomic man-machine interface incorporating adaptive pattern recognition based control system \n",
      "USRE48056 \n",
      "USRE47908 \n",
      "CN107944340A A kind of combination is directly measured and the pedestrian of indirect measurement recognition methods again  - failed \n",
      "WO2019007524A1 Tracking objects in sequences of digital images \n",
      "US9535563 Internet appliance system and method \n",
      "US10361802 Adaptive pattern recognition based control system and method \n",
      " surveil\n",
      "US10250809 Video stabilization system and method \n",
      "US9330315 Determining foregroundness of an object in surveillance video data \n",
      "US9727785 Method and apparatus for tracking targets \n",
      "US10176405 Vehicle re-identification techniques using neural networks for image analysis, viewpoint-aware pattern recognition, and generation of multi- view vehicle representations \n",
      "US9715639 Method and apparatus for detecting targets \n",
      " surveillance\n",
      "US10438055 Human facial detection and recognition system \n",
      "WO2016159199A1 Method for re-identification of objects \n",
      "US10618673 Systems and methods for dynamic planning and operation of autonomous systems using image observation and information theory \n",
      "WO2019052917A1 Subject identification systems and methods \n",
      "CN103959330A Systems and methods for matching visual object components "
     ]
    }
   ],
   "source": [
    "'''Find examples in patents'''\n",
    "n_examples = 5  # number of example sentences desired \n",
    "\n",
    "codes_info = {}\n",
    "for code in codes_of_interest:\n",
    "    keywords_info = []\n",
    "    for keyword in codes[code][:]:\n",
    "        print('\\n', keyword)\n",
    "        keyword_patents = set(all_papers[keyword].sum())\n",
    "        titles = []\n",
    "        for patent in list(keyword_patents):\n",
    "            print(patent, end=\" \")\n",
    "            url = get_patent_url(patent)\n",
    "            title = get_patent_title(patent, patent_dir)\n",
    "            if title not in titles:  # for one keyword, all patents should be unique\n",
    "                print(title, end=\" \")\n",
    "                try:\n",
    "                    div = find_example_div(patent, keyword, patent_dir)\n",
    "                    div = re.sub('<[^>]*>', '', div)  # remove html tags inside div\n",
    "                    sentence = find_example_sentence(div, keyword)\n",
    "                    keywords_info.append((keyword, patent, url, title, sentence, div))\n",
    "                except AttributeError:\n",
    "                    print(' - failed', end=' ')\n",
    "                    keywords_info.append((keyword, patent, url, title, '', ''))\n",
    "                titles.append(title)\n",
    "                if len(titles) == n_examples:  # check if we're done finding patents\n",
    "                    break\n",
    "            print()\n",
    "    columns=['keyword', 'patent', 'url', 'title', 'sentence', 'section']\n",
    "    codes_info[code] = pd.DataFrame(keywords_info, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "24a28b9d-df92-4a2e-972e-184f57bd8ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>patent</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>surveil</td>\n",
       "      <td>US10250809</td>\n",
       "      <td>https://patents.google.com/patent/US10250809/en</td>\n",
       "      <td>Video stabilization system and method</td>\n",
       "      <td>For example, if a camera is mounted to survei...</td>\n",
       "      <td>In many typical applications, it is desirable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surveil</td>\n",
       "      <td>US9330315</td>\n",
       "      <td>https://patents.google.com/patent/US9330315/en</td>\n",
       "      <td>Determining foregroundness of an object in sur...</td>\n",
       "      <td>The present invention relates generally to the...</td>\n",
       "      <td>The present invention relates generally to the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surveil</td>\n",
       "      <td>US9727785</td>\n",
       "      <td>https://patents.google.com/patent/US9727785/en</td>\n",
       "      <td>Method and apparatus for tracking targets</td>\n",
       "      <td>As one example, an unmanned aerial vehicle (U...</td>\n",
       "      <td>Sensor devices are oftentimes used to generate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surveil</td>\n",
       "      <td>US10176405</td>\n",
       "      <td>https://patents.google.com/patent/US10176405/en</td>\n",
       "      <td>Vehicle re-identification techniques using neu...</td>\n",
       "      <td>This technology is useful in a variety of dif...</td>\n",
       "      <td>Generally speaking, vehicle re-identification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surveil</td>\n",
       "      <td>US9715639</td>\n",
       "      <td>https://patents.google.com/patent/US9715639/en</td>\n",
       "      <td>Method and apparatus for detecting targets</td>\n",
       "      <td>As one example, an unmanned aerial vehicle (U...</td>\n",
       "      <td>Target detection may be performed in a number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>surveillance</td>\n",
       "      <td>US10438055</td>\n",
       "      <td>https://patents.google.com/patent/US10438055/en</td>\n",
       "      <td>Human facial detection and recognition system</td>\n",
       "      <td>In one particular embodiment, the at least tw...</td>\n",
       "      <td>Referring now to FIG. 10A, process 2000 begins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>surveillance</td>\n",
       "      <td>WO2016159199A1</td>\n",
       "      <td>https://patents.google.com/patent/WO2016159199...</td>\n",
       "      <td>Method for re-identification of objects</td>\n",
       "      <td>This invention relates generally to computer ...</td>\n",
       "      <td>This invention relates generally to computer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>surveillance</td>\n",
       "      <td>US10618673</td>\n",
       "      <td>https://patents.google.com/patent/US10618673/en</td>\n",
       "      <td>Systems and methods for dynamic planning and o...</td>\n",
       "      <td>Since they are generally quite maneuverable, ...</td>\n",
       "      <td>Remotely-piloted small UAVs (sUAVs) are increa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>surveillance</td>\n",
       "      <td>WO2019052917A1</td>\n",
       "      <td>https://patents.google.com/patent/WO2019052917...</td>\n",
       "      <td>Subject identification systems and methods</td>\n",
       "      <td>Techniques described herein may also be appli...</td>\n",
       "      <td>investigation. Techniques described herein may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>surveillance</td>\n",
       "      <td>CN103959330A</td>\n",
       "      <td>https://patents.google.com/patent/CN103959330A/en</td>\n",
       "      <td>Systems and methods for matching visual object...</td>\n",
       "      <td>Can implement computing equipment 800 for smal...</td>\n",
       "      <td>Can implement computing equipment 800 for smal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        keyword          patent  \\\n",
       "0       surveil      US10250809   \n",
       "1       surveil       US9330315   \n",
       "2       surveil       US9727785   \n",
       "3       surveil      US10176405   \n",
       "4       surveil       US9715639   \n",
       "5  surveillance      US10438055   \n",
       "6  surveillance  WO2016159199A1   \n",
       "7  surveillance      US10618673   \n",
       "8  surveillance  WO2019052917A1   \n",
       "9  surveillance    CN103959330A   \n",
       "\n",
       "                                                 url  \\\n",
       "0    https://patents.google.com/patent/US10250809/en   \n",
       "1     https://patents.google.com/patent/US9330315/en   \n",
       "2     https://patents.google.com/patent/US9727785/en   \n",
       "3    https://patents.google.com/patent/US10176405/en   \n",
       "4     https://patents.google.com/patent/US9715639/en   \n",
       "5    https://patents.google.com/patent/US10438055/en   \n",
       "6  https://patents.google.com/patent/WO2016159199...   \n",
       "7    https://patents.google.com/patent/US10618673/en   \n",
       "8  https://patents.google.com/patent/WO2019052917...   \n",
       "9  https://patents.google.com/patent/CN103959330A/en   \n",
       "\n",
       "                                               title  \\\n",
       "0              Video stabilization system and method   \n",
       "1  Determining foregroundness of an object in sur...   \n",
       "2          Method and apparatus for tracking targets   \n",
       "3  Vehicle re-identification techniques using neu...   \n",
       "4         Method and apparatus for detecting targets   \n",
       "5      Human facial detection and recognition system   \n",
       "6            Method for re-identification of objects   \n",
       "7  Systems and methods for dynamic planning and o...   \n",
       "8         Subject identification systems and methods   \n",
       "9  Systems and methods for matching visual object...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0   For example, if a camera is mounted to survei...   \n",
       "1  The present invention relates generally to the...   \n",
       "2   As one example, an unmanned aerial vehicle (U...   \n",
       "3   This technology is useful in a variety of dif...   \n",
       "4   As one example, an unmanned aerial vehicle (U...   \n",
       "5   In one particular embodiment, the at least tw...   \n",
       "6   This invention relates generally to computer ...   \n",
       "7   Since they are generally quite maneuverable, ...   \n",
       "8   Techniques described herein may also be appli...   \n",
       "9  Can implement computing equipment 800 for smal...   \n",
       "\n",
       "                                             section  \n",
       "0  In many typical applications, it is desirable ...  \n",
       "1  The present invention relates generally to the...  \n",
       "2  Sensor devices are oftentimes used to generate...  \n",
       "3  Generally speaking, vehicle re-identification ...  \n",
       "4  Target detection may be performed in a number ...  \n",
       "5  Referring now to FIG. 10A, process 2000 begins...  \n",
       "6   This invention relates generally to computer ...  \n",
       "7  Remotely-piloted small UAVs (sUAVs) are increa...  \n",
       "8  investigation. Techniques described herein may...  \n",
       "9  Can implement computing equipment 800 for smal...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes_info[code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "281e9f97-e4e5-49f6-8d7d-886ac3becd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>patent</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td>US8050463</td>\n",
       "      <td>https://patents.google.com/patent/US8050463/en</td>\n",
       "      <td>Iris recognition system having image quality m...</td>\n",
       "      <td>More particularly, the invention pertains to ...</td>\n",
       "      <td>The present invention pertains to recognition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iris</td>\n",
       "      <td>US10289908</td>\n",
       "      <td>https://patents.google.com/patent/US10289908/en</td>\n",
       "      <td>Method, apparatus, and computer program produc...</td>\n",
       "      <td>The method may further include estimating a f...</td>\n",
       "      <td>In some embodiments, a method may be provided ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iris</td>\n",
       "      <td>US8761458</td>\n",
       "      <td>https://patents.google.com/patent/US8761458/en</td>\n",
       "      <td>System for iris detection, tracking and recogn...</td>\n",
       "      <td>More particularly, the invention pertains to ...</td>\n",
       "      <td>The present invention pertains to recognition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iris</td>\n",
       "      <td>CN104735361A</td>\n",
       "      <td>https://patents.google.com/patent/CN104735361A/en</td>\n",
       "      <td>Method and apparatus for acquiring a set of im...</td>\n",
       "      <td>It should be understood that imaging device ca...</td>\n",
       "      <td>It should be understood that imaging device ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>finger</td>\n",
       "      <td>US9349039</td>\n",
       "      <td>https://patents.google.com/patent/US9349039/en</td>\n",
       "      <td>Gesture recognition device and control method ...</td>\n",
       "      <td>The gesture expressed by a shape of FINGERs i...</td>\n",
       "      <td>A gesture is extracted from the image by detec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>finger</td>\n",
       "      <td>US9046962</td>\n",
       "      <td>https://patents.google.com/patent/US9046962/en</td>\n",
       "      <td>Methods, systems, apparatuses, circuits and as...</td>\n",
       "      <td>(1990) gave a review of academic research on ...</td>\n",
       "      <td>Sears et al. (1990) gave a review of academic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>finger</td>\n",
       "      <td>US9412003</td>\n",
       "      <td>https://patents.google.com/patent/US9412003/en</td>\n",
       "      <td>Discriminant function specifying device, discr...</td>\n",
       "      <td>For example, the multiple feature quantities ...</td>\n",
       "      <td>It is preferable in the biometric identificati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>finger</td>\n",
       "      <td>US10163215</td>\n",
       "      <td>https://patents.google.com/patent/US10163215/en</td>\n",
       "      <td>Object learning and recognition method and system</td>\n",
       "      <td>Referring to FIG. 4, when an object is a righ...</td>\n",
       "      <td>Referring to FIG. 2, when an object is a regul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>finger</td>\n",
       "      <td>US9684171</td>\n",
       "      <td>https://patents.google.com/patent/US9684171/en</td>\n",
       "      <td>See-through computer display systems</td>\n",
       "      <td>For example, the user may be able to take a s...</td>\n",
       "      <td>The pen 1500 may also include a number of phys...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword        patent                                                url  \\\n",
       "0     iris                                                                    \n",
       "0     iris     US8050463     https://patents.google.com/patent/US8050463/en   \n",
       "1     iris    US10289908    https://patents.google.com/patent/US10289908/en   \n",
       "2     iris     US8761458     https://patents.google.com/patent/US8761458/en   \n",
       "3     iris  CN104735361A  https://patents.google.com/patent/CN104735361A/en   \n",
       "..     ...           ...                                                ...   \n",
       "55  finger     US9349039     https://patents.google.com/patent/US9349039/en   \n",
       "56  finger     US9046962     https://patents.google.com/patent/US9046962/en   \n",
       "57  finger     US9412003     https://patents.google.com/patent/US9412003/en   \n",
       "58  finger    US10163215    https://patents.google.com/patent/US10163215/en   \n",
       "59  finger     US9684171     https://patents.google.com/patent/US9684171/en   \n",
       "\n",
       "                                                title  \\\n",
       "0                                                       \n",
       "0   Iris recognition system having image quality m...   \n",
       "1   Method, apparatus, and computer program produc...   \n",
       "2   System for iris detection, tracking and recogn...   \n",
       "3   Method and apparatus for acquiring a set of im...   \n",
       "..                                                ...   \n",
       "55  Gesture recognition device and control method ...   \n",
       "56  Methods, systems, apparatuses, circuits and as...   \n",
       "57  Discriminant function specifying device, discr...   \n",
       "58  Object learning and recognition method and system   \n",
       "59               See-through computer display systems   \n",
       "\n",
       "                                             sentence  \\\n",
       "0                                                       \n",
       "0    More particularly, the invention pertains to ...   \n",
       "1    The method may further include estimating a f...   \n",
       "2    More particularly, the invention pertains to ...   \n",
       "3   It should be understood that imaging device ca...   \n",
       "..                                                ...   \n",
       "55   The gesture expressed by a shape of FINGERs i...   \n",
       "56   (1990) gave a review of academic research on ...   \n",
       "57   For example, the multiple feature quantities ...   \n",
       "58   Referring to FIG. 4, when an object is a righ...   \n",
       "59   For example, the user may be able to take a s...   \n",
       "\n",
       "                                              section  \n",
       "0                                                      \n",
       "0   The present invention pertains to recognition ...  \n",
       "1   In some embodiments, a method may be provided ...  \n",
       "2   The present invention pertains to recognition ...  \n",
       "3   It should be understood that imaging device ca...  \n",
       "..                                                ...  \n",
       "55  A gesture is extracted from the image by detec...  \n",
       "56  Sears et al. (1990) gave a review of academic ...  \n",
       "57  It is preferable in the biometric identificati...  \n",
       "58  Referring to FIG. 2, when an object is a regul...  \n",
       "59  The pen 1500 may also include a number of phys...  \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Save in pretty format'''\n",
    "codes_tables = {}\n",
    "for code in codes_info:\n",
    "    table = codes_info[code]\n",
    "    table.sentence = table.apply(lambda row: row.sentence.replace(row.keyword, row.keyword.upper()), axis=1)  # capitalize keyword\n",
    "    table.section = table.apply(lambda row: row.section.replace(row.keyword, row.keyword.upper()), axis=1)  # capitalize keyword\n",
    "    mini_tables = [pd.concat([pd.DataFrame([(keyword,'','','','','')], columns=columns), table.query(f'keyword == \"{keyword}\"')]) # keyword's minitable\n",
    "                   for keyword in table.keyword.unique()]\n",
    "    table = pd.concat(mini_tables)\n",
    "    codes_tables[code] = table\n",
    "    \n",
    "# Write to xlsx file\n",
    "with pd.ExcelWriter(join(data_dir, 'keyword_examples.xlsx')) as writer:\n",
    "    for code, table in codes_tables.items():\n",
    "        table.to_excel(writer, sheet_name=code)\n",
    "        \n",
    "# Show first\n",
    "display(codes_tables[list(codes_tables)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3ea36d38-3dab-44d8-8ba9-526883495cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>patent</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>sentence</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iris</td>\n",
       "      <td>US8050463</td>\n",
       "      <td>https://patents.google.com/patent/US8050463/en</td>\n",
       "      <td>Iris recognition system having image quality m...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iris</td>\n",
       "      <td>US10289908</td>\n",
       "      <td>https://patents.google.com/patent/US10289908/en</td>\n",
       "      <td>Method, apparatus, and computer program produc...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iris</td>\n",
       "      <td>US8761458</td>\n",
       "      <td>https://patents.google.com/patent/US8761458/en</td>\n",
       "      <td>System for iris detection, tracking and recogn...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iris</td>\n",
       "      <td>CN104735361A</td>\n",
       "      <td>https://patents.google.com/patent/CN104735361A/en</td>\n",
       "      <td>Method and apparatus for acquiring a set of im...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>finger</td>\n",
       "      <td>US9349039</td>\n",
       "      <td>https://patents.google.com/patent/US9349039/en</td>\n",
       "      <td>Gesture recognition device and control method ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>finger</td>\n",
       "      <td>US9046962</td>\n",
       "      <td>https://patents.google.com/patent/US9046962/en</td>\n",
       "      <td>Methods, systems, apparatuses, circuits and as...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>finger</td>\n",
       "      <td>US9412003</td>\n",
       "      <td>https://patents.google.com/patent/US9412003/en</td>\n",
       "      <td>Discriminant function specifying device, discr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>finger</td>\n",
       "      <td>US10163215</td>\n",
       "      <td>https://patents.google.com/patent/US10163215/en</td>\n",
       "      <td>Object learning and recognition method and system</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>finger</td>\n",
       "      <td>US9684171</td>\n",
       "      <td>https://patents.google.com/patent/US9684171/en</td>\n",
       "      <td>See-through computer display systems</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   keyword        patent                                                url  \\\n",
       "0     iris                                                                    \n",
       "0     iris     US8050463     https://patents.google.com/patent/US8050463/en   \n",
       "1     iris    US10289908    https://patents.google.com/patent/US10289908/en   \n",
       "2     iris     US8761458     https://patents.google.com/patent/US8761458/en   \n",
       "3     iris  CN104735361A  https://patents.google.com/patent/CN104735361A/en   \n",
       "..     ...           ...                                                ...   \n",
       "55  finger     US9349039     https://patents.google.com/patent/US9349039/en   \n",
       "56  finger     US9046962     https://patents.google.com/patent/US9046962/en   \n",
       "57  finger     US9412003     https://patents.google.com/patent/US9412003/en   \n",
       "58  finger    US10163215    https://patents.google.com/patent/US10163215/en   \n",
       "59  finger     US9684171     https://patents.google.com/patent/US9684171/en   \n",
       "\n",
       "                                                title sentence section  \n",
       "0                                                                       \n",
       "0   Iris recognition system having image quality m...                   \n",
       "1   Method, apparatus, and computer program produc...                   \n",
       "2   System for iris detection, tracking and recogn...                   \n",
       "3   Method and apparatus for acquiring a set of im...                   \n",
       "..                                                ...      ...     ...  \n",
       "55  Gesture recognition device and control method ...                   \n",
       "56  Methods, systems, apparatuses, circuits and as...                   \n",
       "57  Discriminant function specifying device, discr...                   \n",
       "58  Object learning and recognition method and system                   \n",
       "59               See-through computer display systems                   \n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Save in format that will look nice in google sheets'''\n",
    "table = codes_info['body_parts']\n",
    "table.sentence = table.apply(lambda row: row.sentence.replace(row.keyword, row.keyword.upper()), axis=1)  # capitalize keyword\n",
    "table.section = table.apply(lambda row: row.section.replace(row.keyword, row.keyword.upper()), axis=1)  # capitalize keyword\n",
    "mini_tables = [pd.concat([pd.DataFrame([(keyword,'','','','','')], columns=columns), table.query(f'keyword == \"{keyword}\"')]) # keyword's minitable\n",
    "               for keyword in table.keyword.unique()]\n",
    "table = pd.concat(mini_tables)\n",
    "# table.loc[table.keyword.duplicated(), 'keyword'] = ''  # only note keyword once\n",
    "display(table)\n",
    "# table.to_csv(join(data_dir, 'keyword_examples.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56383e5c-8088-4b0f-8465-b7ac6ba1e282",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Show current keywords quick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ad18ed0-c558-43c1-9841-64fcd3f5458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surveil: surveil, surveillance\n",
      "\n",
      "hard_crime: prisoner, prison\n",
      "\n",
      "body_parts: iris, irises, face, facial, torso, anatomy, anatomies, limb, hand, finger\n",
      "\n",
      "bodies: pedestrian, foot traffic\n",
      "\n",
      "demographic: ethnicity, gender, female, male, woman, man, sex\n",
      "\n",
      "children: child, children, kid, youth, age\n",
      "\n",
      "scenes: room, office, street, crowd, home, house, apartment, airport\n",
      "\n",
      "hard_movement: travel, license plate, airport, baggage\n",
      "\n",
      "soft_influence: advertisement, purchase\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([code + ': ' + ', '.join(codes[code]) + '\\n' for code in codes_of_interest]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f306efa6-53d4-4589-94c3-61b19429b958",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Recalculate stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34dbcd90-b259-4463-a1ff-a9a453abf9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.5% (608 out of 805) of patenting institutions follow this norm.\n",
      "87.9% (51 out of 58) of patenting countrys follow this norm.\n",
      "72.3% (3071 out of 4247) of patenting fields follow this norm.\n"
     ]
    }
   ],
   "source": [
    "# Quick check prevalence of norm\n",
    "# We see there is a norm that for entitites authoring papers with patents - many are patented for surv. (See paper for more details.)\n",
    "# Quantify how prevalent this norm is.\n",
    "\n",
    "for source in ['Institution', 'Country', 'Field']:\n",
    "    sources = analyze_sources(papers, source)\n",
    "    sources['percent_of_interest'] = sources.n_papers_of_interest / sources.n_papers_patented\n",
    "    n_surveillance_sources = len(sources.query(\"(n_papers_patented > 0) & (percent_of_interest > .5)\"))\n",
    "    n_relevant_sources = len(sources.query(\"(n_papers_patented > 0)\"))\n",
    "    print(f'{100 * n_surveillance_sources / n_relevant_sources:.1f}% ({n_surveillance_sources} out of {n_relevant_sources}) of patenting {source.lower()}s follow this norm.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1198830b-93b4-4674-b5ad-ce61c96c2c15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prevalence of medical words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cf36aab-1b99-4f45-ba02-0042e611d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marked as surv:  14761\n",
      "Marked as surv and not medical:  12755\n",
      "Fracion of surv that are valid:  0.8641013481471445\n"
     ]
    }
   ],
   "source": [
    "patents_marked_as_surv = set(papers.patents_of_interest.sum())\n",
    "patents_marked_as_medical = set(papers.medical.sum())\n",
    "print('Marked as surv: ', len(patents_marked_as_surv))\n",
    "print('Marked as surv and not medical: ', len(patents_marked_as_surv - patents_marked_as_medical))\n",
    "print('Fracion of surv that are valid: ', len(patents_marked_as_surv - patents_marked_as_medical)/len(patents_marked_as_surv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f73aad5-5773-4249-9e5a-aa9b87fcd1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marked as surv:  4426\n",
      "Marked as surv and not medical:  4426\n",
      "Fracion of surv that are valid:  1.0\n"
     ]
    }
   ],
   "source": [
    "papers_marked_as_surv = set(papers.query('n_patents_of_interest > 0').index)\n",
    "papers_marked_as_medical = set(papers[papers.medical_code.apply(len) > 0])\n",
    "print('Marked as surv: ', len(papers_marked_as_surv))\n",
    "print('Marked as surv and not medical: ', len(papers_marked_as_surv - papers_marked_as_medical))\n",
    "print('Fracion of surv that are valid: ', len(papers_marked_as_surv - papers_marked_as_medical)/len(papers_marked_as_surv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a15d76d-c972-4179-a48d-f7e2ff48c170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patents</th>\n",
       "      <th>medical_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaperId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1904325426</th>\n",
       "      <td>US10452920</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904325426</th>\n",
       "      <td>US10380428</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904325426</th>\n",
       "      <td>US10311913</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061320885</th>\n",
       "      <td>US9808549</td>\n",
       "      <td>[US9808549, US9808549]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741327137</th>\n",
       "      <td>WO2019133841A1</td>\n",
       "      <td>[WO2019133841A1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105661278</th>\n",
       "      <td>US10304254</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105661278</th>\n",
       "      <td>US10083522</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105661278</th>\n",
       "      <td>US10068344</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118120587</th>\n",
       "      <td>US7603324</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162401891</th>\n",
       "      <td>US6920375</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42819 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   patents            medical_code\n",
       "PaperId                                           \n",
       "1904325426      US10452920                      []\n",
       "1904325426      US10380428                      []\n",
       "1904325426      US10311913                      []\n",
       "2061320885       US9808549  [US9808549, US9808549]\n",
       "2741327137  WO2019133841A1        [WO2019133841A1]\n",
       "...                    ...                     ...\n",
       "2105661278      US10304254                      []\n",
       "2105661278      US10083522                      []\n",
       "2105661278      US10068344                      []\n",
       "2118120587       US7603324                      []\n",
       "2162401891       US6920375                      []\n",
       "\n",
       "[42819 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers[['patents', 'medical_code']][papers.patents.apply(len) != 0].explode('patents')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5b3cb-5d5d-45b6-87c3-59f4fdae860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "patents = list(set(papers.patents.sum()))\n",
    "patent_keywords = [for patent in patents]\n",
    "for word in keywords_of_interest:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a2f4a-db58-4650-a67b-0bd8a3f26d5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# See which keywords have the strongest effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c61d9e5-fe12-496f-83ce-490a11a6e704",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of papers: 19551. Number of patents: 23471\n"
     ]
    }
   ],
   "source": [
    "# For each word, check its impact on the totals\n",
    "n_papers = len(papers)\n",
    "n_papers_patented = len(papers.query('n_patents > 0'))\n",
    "n_patents = len(set(papers.patents.sum()))\n",
    "print(f'Number of papers: {n_papers}. Number of patents: {n_patents}')\n",
    "word_contributions = {}\n",
    "for word in keywords_of_interest:\n",
    "    mark_interesting(papers, [word])\n",
    "    surv_papers = papers.query(\"n_patents_of_interest > 0\")\n",
    "    surv_patents_list = surv_papers.patents_of_interest.sum()  # including repeats\n",
    "    n_surv_patents = len(set(surv_patents_list)) if surv_patents_list else 0\n",
    "    word_contributions[word] = 100*len(surv_papers)/n_papers_patented\n",
    "    # if n_surv_patents/n_patents < .01:  # percent of patents \n",
    "    # print(f'{word}:\\n {100*len(surv_papers)/n_papers_patented:2.1f}% of patented papers lead to a patent with this word. {100*n_surv_patents/n_patents:2.1f}% of patents have this word.')\n",
    "    # for source in ['Institution', 'Country', 'Field']:\n",
    "    #     sources = analyze_sources(all_papers, source)\n",
    "    #     sources['percent_of_interest'] = sources.n_papers_of_interest / sources.n_papers_patented\n",
    "    #     n_surveillance_sources = len(sources.query(\"(n_papers_patented > 0) & (percent_of_interest > .5)\"))\n",
    "    #     n_relevant_sources = len(sources.query(\"(n_papers_patented > 0)\"))\n",
    "    #     print(f'{100 * n_surveillance_sources / n_relevant_sources:.1f}% ({n_surveillance_sources} out of {n_relevant_sources}) of {source.lower()}s follow this norm.')\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9bd1a10-a0e6-4e35-b734-4673ef21a23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('face', 43.53472614342179),\n",
       " ('hand', 30.980613589309243),\n",
       " ('facial', 25.898738942217204),\n",
       " ('surveillance', 19.047619047619047),\n",
       " ('room', 18.539431582909845),\n",
       " ('travel', 18.501788067005457),\n",
       " ('home', 15.847920195746283),\n",
       " ('finger', 14.624505928853756),\n",
       " ('pedestrian', 13.250517598343686),\n",
       " ('office', 12.234142668925278),\n",
       " ('street', 11.76359872012046),\n",
       " ('child', 11.537737624694147),\n",
       " ('age', 10.107284020327498),\n",
       " ('house', 10.013175230566535),\n",
       " ('advertisement', 8.300395256916996),\n",
       " ('purchase', 7.942781855825334),\n",
       " ('crowd', 6.60643704121965),\n",
       " ('torso', 6.305288913984566),\n",
       " ('man', 6.230001882175795),\n",
       " ('male', 5.853566723131941),\n",
       " ('gender', 5.740636175418784),\n",
       " ('children', 5.740636175418784),\n",
       " ('iris', 5.420666290231508),\n",
       " ('limb', 4.81837003576134),\n",
       " ('female', 4.81837003576134),\n",
       " ('license plate', 4.573687182382835),\n",
       " ('anatomy', 4.498400150574064),\n",
       " ('airport', 3.5384904950122342),\n",
       " ('woman', 1.976284584980237),\n",
       " ('sex', 1.8257105213626952),\n",
       " ('ethnicity', 1.6563146997929608),\n",
       " ('irises', 0.9787314135140223),\n",
       " ('kid', 0.9034443817052513),\n",
       " ('apartment', 0.846979107848673),\n",
       " ('baggage', 0.6211180124223602),\n",
       " ('prison', 0.3764351590438547),\n",
       " ('anatomies', 0.35761340109166195),\n",
       " ('youth', 0.282326369282891),\n",
       " ('surveil', 0.24468285337850557),\n",
       " ('foot traffic', 0.13175230566534915),\n",
       " ('prisoner', 0.09410878976096368)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_contributions.items(), key=lambda word_contribution: word_contribution[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79da1b86-0d1b-495a-807a-d1f6ab1b0334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For each word, check its impact on the totals\n",
    "# n_papers = len(all_papers)\n",
    "# n_papers_patented = len(all_papers.query('n_patents > 0'))\n",
    "# n_patents = len(set(all_papers.patents.sum()))\n",
    "# print(f'Number of papers: {n_papers}. Number of patents: {n_patents}')\n",
    "# # If you use all words\n",
    "# all_words = sum([codes[code] for code in codes_of_interest], [])\n",
    "# fraction_surv_papers = len(all_papers.query(\"n_patents_of_interest > 0\")) / n_papers_patented\n",
    "# # If you drop a word\n",
    "# print('Dropping...')\n",
    "# for _ in range(30):\n",
    "#     word_impacts = []\n",
    "#     for word in all_words:\n",
    "#         words = all_words.copy()\n",
    "#         words.remove(word)\n",
    "#         mark_interesting(all_papers, words)\n",
    "#         surv_papers = all_papers.query(\"n_patents_of_interest > 0\")\n",
    "#         surv_patents_list = surv_papers.patents_of_interest.sum()  # including repeats\n",
    "#         n_surv_patents = len(set(surv_patents_list)) if surv_patents_list else 0\n",
    "#         word_impacts.append((word, len(surv_papers)/n_papers_patented - fraction_surv_papers))\n",
    "#     worst_word, drop = sorted(word_impacts, key=lambda word_drop: word_drop[1])[-1]\n",
    "#     print(worst_word, drop)\n",
    "#     all_words.remove(worst_word)\n",
    "\n",
    "# all_papers = filter_paper_years(load_papers())\n",
    "# mark_interesting(all_papers, all_words)\n",
    "# # Quick check prevalence of norm\n",
    "# # We see there is a norm that for entitites authoring papers with patents, at least half are used in surveillance. (See paper for more details.)\n",
    "# # Quantify how prevalent this norm is\n",
    "# for source in ['Institution', 'Country', 'Field']:\n",
    "#     sources = analyze_sources(all_papers, source)\n",
    "#     sources['percent_of_interest'] = sources.n_papers_of_interest / sources.n_papers_patented\n",
    "#     n_surveillance_sources = len(sources.query(\"(n_papers_patented > 0) & (percent_of_interest > .5)\"))\n",
    "#     n_relevant_sources = len(sources.query(\"(n_papers_patented > 0)\"))\n",
    "#     print(f'{100 * n_surveillance_sources / n_relevant_sources:.1f}% ({n_surveillance_sources} out of {n_relevant_sources}) of {source.lower()}s follow this norm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c35e6d7-650e-439b-9376-62f935c41422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "what-is-ai-for",
   "language": "python",
   "name": "what-is-ai-for"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
