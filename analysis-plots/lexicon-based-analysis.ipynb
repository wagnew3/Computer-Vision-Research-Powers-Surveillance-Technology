{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdcc27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install plotly pandas numpy nbformat scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c9b24-5635-4a03-9e6a-a808d85215ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and parameters\n",
    "data_dir = 'data'\n",
    "paper_info_filename = 'cvpr_paper_info_and_keywords.pkl'\n",
    "paper_extra_info_filename = 'cvpr_papers_to_all_patents'\n",
    "countries_filename = 'country-codes.txt'\n",
    "elite_univs_filename = 'elite_universities.txt'\n",
    "codes_filename = \"final_keywords.txt\"\n",
    "stopwords_filename = 'stopwords.txt'\n",
    "codes_of_interest = [\"final\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e0513-004c-4ca1-836f-c294989a1a66",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b6f11-19c1-46d9-a5cc-d71e56e18d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from pathlib import Path\n",
    "(figs_dir := Path(data_dir) / '..' / 'figures').mkdir(exist_ok=True)\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import os\n",
    "from os.path import join\n",
    "from itertools import chain\n",
    "import plotly.graph_objects as go\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import pickle\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio; pio.renderers.default = \"iframe\"\n",
    "\n",
    "np.random.seed(1991)\n",
    "plotly.offline.init_notebook_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fff160-b892-4a1b-9309-17bc747b55c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_lists(filepath, filter_comments=True):\n",
    "    '''Read a file containing codes in our special format and return a dictionary of the codes'''\n",
    "    with open(filepath) as f:\n",
    "        d = {section.split('\\n')[0].strip('## '): [item for item in section.strip().split('\\n')[1:] if item]  # code to keywords\n",
    "             for section in f.read().split('\\n\\n')}  # for each code's section\n",
    "    if filter_comments:\n",
    "        d = {key: [item.split('#')[0].strip() for item in d[key] if not item.startswith('#')] for key in d}  # keep real part of valid lines\n",
    "        for key in list(d):\n",
    "            if d[key] == []:  # delete codes with no items\n",
    "                del d[key]\n",
    "    return d\n",
    "\n",
    "def print_lists(lists):\n",
    "    print('\\n'.join([header + ': ' + ', '.join(lists[header]) + '\\n' for header in lists]))\n",
    "    \n",
    "def load_papers():\n",
    "    '''Load all papers and info into a Pandas DataFrame, annotated with codes'''\n",
    "    papers = (pd.read_pickle(os.path.join(data_dir, paper_info_filename))\n",
    "              .rename_axis('PaperId')  # Rename index\n",
    "              .rename(dict(DisplayName='Institution', DisplayName_fields='Field'), axis=1))  # Rename some columns\n",
    "    # Load papers' patents\n",
    "    papers_patents = pickle.load(open(os.path.join(data_dir, paper_extra_info_filename), 'rb'))\n",
    "    papers_patents = DataFrame(papers_patents.items(), columns=['PaperId',  'patents']).set_index('PaperId')  # Convert to Dataframe\n",
    "    papers_patents.patents = papers_patents.patents.apply(lambda patents: [p.replace('-', '') for p in patents])\n",
    "    # Combine and clean\n",
    "    papers = papers.join(papers_patents)\n",
    "    papers.patents = papers.patents.fillna(\"\").apply(list)\n",
    "    for col in ['PaperId', 'Latitude', 'Longitude']:  # Clean columns that say the same info multiple times\n",
    "        papers[col] = papers[col].apply(lambda vals: vals[0])\n",
    "    papers.Year = papers.Year.astype(int)  # Convert year column from strings to integers\n",
    "    papers['Decade'] = papers.Year.apply(lambda year: 10 * (year//10))  # Save decade\n",
    "    # Aggregate keyword columns into code columns\n",
    "    codes = read_lists(os.path.join(data_dir, codes_filename))\n",
    "    for code, keywords in codes.items():\n",
    "        papers[f'{code}_code'] = papers[keywords].sum(axis=1)\n",
    "    # Add whether a paper was ever cited in a patent (either of the following two lines have the same result)\n",
    "    papers['n_patents'] = papers.patents.apply(len)\n",
    "    # papers['n_patents'] = papers['keyword_depth_vec'].apply(lambda cites: int(cites[0,:,0].sum()))\n",
    "    return papers\n",
    "\n",
    "def filter_paper_years(papers, year_range=range(1990, 2022), years_to_drop=[1990, 1995, 2002]):\n",
    "    '''Filter papers DataFrame to requested years and return updated Pandas DataFrame.\n",
    "    The defaults result in limiting to the years we view as reliable data.'''\n",
    "    return papers.query('(Year in @year_range) & (Year not in @years_to_drop)')\n",
    "\n",
    "def mark_interesting(papers, codes_of_interest):\n",
    "    '''Given papers DataFrame and which codes are of interest (list of strings),\n",
    "    add columns indicating which papers are of interest and related info'''\n",
    "    papers['patents_of_interest'] = papers[codes_of_interest].sum(axis=1).apply(set).apply(list)\n",
    "    papers['n_patents_of_interest'] = papers.patents_of_interest.apply(len)\n",
    "    papers['n_patents_not_of_interest'] = papers.n_patents - papers.n_patents_of_interest\n",
    "\n",
    "def analyze_sources(papers, source):\n",
    "    '''Given papers DataFrame and desired source type for analysis\n",
    "    (string, e.g. Institution, Country, Field, Year, or Decade),\n",
    "    collect and return institutions DataFrame'''\n",
    "    # Each link between a source and a paper+details\n",
    "    # (e.g. a paper affiliated with U.S. and China has two otherwise identical rows)\n",
    "    if source == 'Country':  # Extra step before\n",
    "        source = 'Iso3166Code'\n",
    "    links = (papers[[source, 'PaperId', 'patents', 'n_patents', 'patents_of_interest', 'n_patents_of_interest']]\n",
    "             .explode(source)  # each paper has multiple links\n",
    "             .drop_duplicates(['PaperId', source])  # remove duplicate links\n",
    "             .reset_index(drop=True))\n",
    "    if source == 'Iso3166Code':  # Extra step after\n",
    "        source = 'Country'\n",
    "        countries = dict([line.strip().split('\\t') for line in open(os.path.join(data_dir, countries_filename)).readlines()])\n",
    "        links.insert(0, 'Country', links.Iso3166Code.replace(countries))\n",
    "    # Summarize the sources' downstream patents\n",
    "    sources_general_info = links.groupby(source).agg(dict(PaperId=list, patents=sum)).rename(dict(PaperId='papers'), axis=1)\n",
    "    sources_general_info.patents = sources_general_info.patents.apply(set).apply(list)  # drop duplicate patents\n",
    "    sources_patent_info = links.query('n_patents > 0').groupby(source).agg(dict(PaperId=list)).rename(dict(PaperId='papers_patented'), axis=1)\n",
    "    sources_info_of_interest = links.query('n_patents_of_interest > 0').groupby(source).agg(dict(PaperId=list, patents_of_interest=sum)).rename(dict(PaperId='papers_of_interest'), axis=1)\n",
    "    sources_info_of_interest.patents_of_interest = sources_info_of_interest.patents_of_interest.apply(set).apply(list)  # drop duplicate patents\n",
    "    sources = sources_general_info.join([sources_patent_info, sources_info_of_interest]).reset_index()\n",
    "    for col in ['papers', 'papers_patented', 'patents', 'papers_of_interest', 'patents_of_interest']:\n",
    "        sources[col] = sources[col].fillna(\"\").apply(list)\n",
    "        sources[f'n_{col}'] = sources[col].apply(len)\n",
    "    # Drop generic sources\n",
    "    if source == 'Field':\n",
    "        generic_fields = [\n",
    "            'Artificial intelligence', 'Computer vision', 'Pattern recognition', 'Mathematics', 'Computer science',\n",
    "            'Machine learning', 'Deep learning', 'Algorithm', '(', 'Convolutional neural net', 'Pixel', 'Artificial neural networks']\n",
    "        sources = sources[~sources.Field.apply(lambda field: any([generic_field.lower() in field.lower() for generic_field in generic_fields]))]\n",
    "    # Clean\n",
    "    sources = sources.replace('French Institute for Research in Computer Science and Automation', 'IRIA')\n",
    "    sources = sources.replace('Korea Advanced Institute of Science and Technology', 'Korea Advanced Inst. of Science & Tech.')\n",
    "    sources = sources.replace('University of Illinois Urbana-Champaign', 'Urbana-Champaign')\n",
    "    sources = sources.replace('University of California, Berkeley', 'Berkeley')\n",
    "    sources = sources.replace('Massachusetts Institute of Technology', 'MIT')\n",
    "    sources = sources.replace('Cognitive neuroscience of visual object recognition', 'CogSci of object recognition')\n",
    "    if source == 'Institution':\n",
    "        sources.Institution = sources.Institution.apply(lambda name: name.replace('University', 'Univ.'))\n",
    "    if source == 'Decade':\n",
    "        decades_of_interest = [1990, 2010]\n",
    "        sources = sources.query('Decade in @decades_of_interest')\n",
    "    return sources\n",
    "\n",
    "\n",
    "def _compute_error_bars(row, n_tries: int = 1000):\n",
    "    '''\n",
    "    Function to compute error bars; use with df.apply()\n",
    "    Error is estimated by using a bootstrap method.\n",
    "    Positive and negative samples are drawn with replacement from the original data over `n_tries` iterations.\n",
    "    The error is the standard deviation of the number of positive samples over the iterations.\n",
    "    '''\n",
    "    pos = row.n_papers_of_interest\n",
    "    neg = row.n_papers_patented - row.n_papers_of_interest\n",
    "    to_sample = np.concatenate((np.ones(pos, dtype=int), np.zeros(neg, dtype=int)))\n",
    "\n",
    "    sampled_n_patents_of_interest = []\n",
    "    sampled_n_patents_not_of_interest = []\n",
    "    for _ in range(n_tries):\n",
    "        sampled = np.random.choice(to_sample, size=len(to_sample), replace=True)\n",
    "        sampled_n_patents_of_interest.append(np.sum(sampled))\n",
    "        sampled_n_patents_not_of_interest.append(np.sum(1 - sampled))\n",
    "\n",
    "    row['n_patents_not_of_interest'] = neg\n",
    "    row['n_patents_of_interest_error'] = np.std(sampled_n_patents_of_interest)\n",
    "    row['n_patents_not_of_interest_error'] = np.std(sampled_n_patents_not_of_interest)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "def compute_error_bars(papers, n_tries: int = 1000):\n",
    "    '''\n",
    "    Compute error bars for the entire papers DataFrame.\n",
    "    '''\n",
    "    papers = papers.apply(_compute_error_bars, axis=1, args=(n_tries,))\n",
    "    return papers\n",
    "\n",
    "def code_name(code):\n",
    "    return f'{code}_code'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6dcc6c-9f26-4e7a-9c05-6b4636115e7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a2cd15-f15d-4526-a4e8-f6873bbbfbe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "papers = load_papers()\n",
    "papers.drop(columns=[\"keyword_depth_vec\", \"keyword_depth_vec_fields\", \"PaperId_fields\"], inplace=True)\n",
    "all_papers = filter_paper_years(papers).copy()\n",
    "codes = read_lists(join(data_dir, codes_filename))\n",
    "print_lists({code: codes[code] for code in codes_of_interest})\n",
    "mark_interesting(all_papers, map(code_name, codes_of_interest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3860c670-6fe5-43b6-800b-ee6035d8fd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check prevalence of norm\n",
    "# We see there is a norm that for entitites authoring papers with patents, at least half are used in surveillance. (See paper for more details.)\n",
    "# Quantify how prevalent this norm is\n",
    "for source in ['Institution', 'Country', 'Field']:\n",
    "    sources = analyze_sources(all_papers, source)\n",
    "    sources['percent_of_interest'] = sources.n_papers_of_interest / sources.n_papers_patented\n",
    "    n_surveillance_sources = len(sources.query(\"(n_papers_patented > 0) & (percent_of_interest > .5)\"))\n",
    "    n_relevant_sources = len(sources.query(\"(n_papers_patented > 0)\"))\n",
    "    print(f'{100 * n_surveillance_sources / n_relevant_sources:.1f}% ({n_surveillance_sources} out of {n_relevant_sources}) of {source.lower()}s follow this norm.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0f4170-82fb-4991-8c4d-6e6100d02c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patents = len(set([p for ps in all_papers['patents'].to_list() for p in ps]))\n",
    "num_patents_of_interest = len(set([p for ps in all_papers['patents_of_interest'].to_list() for p in ps]))\n",
    "\n",
    "print(f'Number of papers: {len(all_papers):,}')\n",
    "print(f'Number of patents: {num_patents:,}')\n",
    "print(f'Number of patents of interest: {num_patents_of_interest:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8b809-14d8-4a6b-837f-effa82346fbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf43c50-01a0-47f6-8196-5894c29d7280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_sources_percents(papers, source, filt=None, sort='n_papers', n=None,\n",
    "                               color='MediumTurquoise', line=False, error_color='darkgrey',\n",
    "                               background_stack: bool = True, whisk_width=0, whisk_thick=2, condensed_bars=False, **kwargs):\n",
    "    '''\n",
    "    Visualize the mapping from sources to percents of interest.\n",
    "\n",
    "    papers: DataFrame  -- Paper info\n",
    "    source: str -- Source type of interest (e.g. Institution, Country, Year, etc)\n",
    "    filt: str -- Pandas-style query that will filter down which sources will be included in the figure\n",
    "    sort: str -- Property that will sort the sources before creating the figure\n",
    "    n: int -- Number of sources to include in figure\n",
    "    color: str -- Color of main bars\n",
    "    line: bool -- Should a line be added as a 50% marker?\n",
    "    kwargs -- All other args are assumed to be plotly figure parameters that will be passed along\n",
    "    '''\n",
    "    # Get sources, filter, and sort\n",
    "    sources = analyze_sources(papers, source)\n",
    "    print(f\"We consider {len(set(sources.papers.sum()))} papers.\")\n",
    "    if filt: sources = sources.query(filt)\n",
    "    if sort: sources = sources.sort_values(sort, ascending=False)[:n]\n",
    "    print(f\"We plot {len(set(sources.papers.sum()))} papers.\")\n",
    "\n",
    "    sources = compute_error_bars(sources)\n",
    "\n",
    "    # New columns\n",
    "    sources['Percent used in surveillance patents'] = 100 * sources.n_papers_of_interest / sources.n_papers_patented\n",
    "    sources['Percent not used in surveillance patents'] = 100 - sources['Percent used in surveillance patents']\n",
    "    sources['Percent error surveillance patents'] = 100 * sources.n_patents_of_interest_error / sources.n_papers_patented\n",
    "    sources['Percent error not surveillance patents'] = 100 * sources.n_patents_not_of_interest_error / sources.n_papers_patented\n",
    "\n",
    "    # Visualize\n",
    "    fig = go.Figure()\n",
    "    if background_stack:\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                name='Percent not used in surveillance patents',\n",
    "                x=sources[source],\n",
    "                y=sources['Percent not used in surveillance patents'],\n",
    "                marker_color='lightgrey',\n",
    "                base=sources['Percent used in surveillance patents'],\n",
    "            )\n",
    "        )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name='Percent used in surveillance patents',\n",
    "            x=sources[source],\n",
    "            y=sources['Percent used in surveillance patents'],\n",
    "            marker_color=color,\n",
    "            error_y={\n",
    "                'type': 'data',\n",
    "                'array': sources['Percent error surveillance patents'],\n",
    "                'symmetric': True,\n",
    "                'color': error_color,\n",
    "                'thickness': whisk_thick,\n",
    "                'width': whisk_width\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout()\n",
    "\n",
    "    if line: fig.add_hline(50, line_color='salmon', line_width=5)\n",
    "    if condensed_bars:\n",
    "        fig.update_traces(marker_line_width = 0)\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(title='Papers with downstream patents', title_font_size=15, range=(-2, 100), dtick=50, tickfont_size=15, ticksuffix='%', showgrid=False),\n",
    "        xaxis=dict(dtick=1, tickfont_size=13), legend=dict(title='', xanchor='center', x=.5, yanchor='top', y=1.35, font_size=15),\n",
    "        template='plotly_white', barmode='stack', font_size=15, paper_bgcolor='rgba(0,0,0,0)', bargap=.03)\n",
    "    fig.update_layout(**kwargs)\n",
    "    return fig\n",
    "\n",
    "def visualize_sources_numbers_vertical(\n",
    "        papers, source, filt=None, sort='n_papers_of_interest', n=None,\n",
    "        color='MediumTurquoise', stackbars=True, error_color='darkgrey', show_error: bool = True,\n",
    "        whisk_width=5, whisk_thick=2, **kwargs):\n",
    "    '''Visualize vertically the mapping from sources to number of papers of interest\n",
    "\n",
    "    papers: DataFrame  -- Paper info\n",
    "    source: str -- Source type of interest (e.g. Institution, Country, Year, etc)\n",
    "    filt: str -- Pandas-style query that will filter down which sources will be included in the figure\n",
    "    sort: str -- Property that will sort the sources before creating the figure\n",
    "    n: int -- Number of sources to include in figure\n",
    "    color: str -- Color of main bars\n",
    "    stackbars: bool -- Should surveillance and non-surveillance bars be stacked or side-by-side?\n",
    "    kwargs -- All other args are assumed to be plotly figure parameters that will be passed along\n",
    "    '''\n",
    "    sources = analyze_sources(papers, source)\n",
    "\n",
    "    # Filter and sort sources\n",
    "    if filt: sources = sources.query(filt)\n",
    "    if sort: sources = sources.sort_values(sort, ascending=False)[:n]\n",
    "    print(f\"We plot {len(set(sources.papers.sum()))} papers.\")\n",
    "\n",
    "    sources = compute_error_bars(sources)\n",
    "\n",
    "    # New columns\n",
    "    surv_label, not_surv_label = 'Number used in surveillance patents', 'Number not used in surveillance patents'\n",
    "    err_surv_label, err_not_surv_label = 'Error surveillance patents', 'Error not surveillance patents'\n",
    "    sources[surv_label] = sources.n_papers_of_interest\n",
    "    sources[not_surv_label] = sources.n_papers_patented - sources.n_papers_of_interest\n",
    "    sources[err_surv_label] = sources.n_patents_of_interest_error\n",
    "    sources[err_not_surv_label] = sources.n_patents_not_of_interest_error\n",
    "\n",
    "    # Visualize\n",
    "    columns_to_plot = [not_surv_label, surv_label] if not stackbars else [surv_label, not_surv_label]\n",
    "    traceorder = 'reversed' if not stackbars else 'normal'\n",
    "    barmode = 'stack' if stackbars else 'group'\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=not_surv_label,\n",
    "            x=sources[source],\n",
    "            y=sources[not_surv_label],\n",
    "            orientation='v',\n",
    "            marker_color='darkgrey',\n",
    "            error_y={\n",
    "                'type': 'data',\n",
    "                'array': sources[err_not_surv_label],\n",
    "                'symmetric': True,\n",
    "                'color': 'grey',\n",
    "                'thickness': whisk_thick,\n",
    "                'width': whisk_width\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=surv_label,\n",
    "            x=sources[source],\n",
    "            y=sources[surv_label],\n",
    "            orientation='v',\n",
    "            marker_color=color,\n",
    "            error_y={\n",
    "                'type': 'data',\n",
    "                'array': sources[err_surv_label],\n",
    "                'symmetric': True,\n",
    "                'color': error_color,\n",
    "                'thickness': whisk_thick,\n",
    "                'width': whisk_width\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        yaxis=dict(title='Number of papers<br>with downstream patents', title_font_size=15, tickfont_size=15, ticksuffix=' '),\n",
    "        xaxis=dict(tickfont_size=15),\n",
    "        legend=dict(title='', xanchor='center', x=.5, yanchor='top', y=1.35, font_size=15, traceorder=traceorder),\n",
    "        template='plotly_white', font_size=15, barmode=barmode, paper_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(**kwargs)\n",
    "    return fig\n",
    "\n",
    "def visualize_sources_numbers_horizontal(papers, source, filt=None, sort='n_papers', n=None, color='MediumTurquoise',\n",
    "                                         error_color='darkgrey', whisk_width=5, whisk_thick=2, insidetext=False, **kwargs):\n",
    "    '''Visualize horizontally the mapping from sources to number of papers of interest\n",
    "\n",
    "    papers: DataFrame  -- Paper info\n",
    "    source: str -- Source type of interest (e.g. Institution, Country, Year, etc)\n",
    "    filt: str -- Pandas-style query that will filter down which sources will be included in the figure\n",
    "    sort: str -- Property that will sort the sources before creating the figure\n",
    "    n: int -- Number of sources to include in figure\n",
    "    color: str -- Color of main bars\n",
    "    kwargs -- All other args are assumed to be plotly figure parameters that will be passed along\n",
    "    '''\n",
    "    sources = analyze_sources(papers, source)\n",
    "\n",
    "    # Filter and sort sources\n",
    "    if filt: sources = sources.query(filt)\n",
    "    if sort: sources = sources.sort_values(sort, ascending=False)[:n].sort_values(sort, ascending=True)\n",
    "    print(f\"We plot {len(set(sources.papers.sum()))} papers.\")\n",
    "\n",
    "    sources = compute_error_bars(sources)\n",
    "\n",
    "    # New columns\n",
    "    surv_label, not_surv_label = 'Used in surveillance patents', 'Not used in surveillance patents'\n",
    "    err_surv_label, err_not_surv_label = 'Error surveillance patents', 'Error not surveillance patents'\n",
    "    sources[surv_label] = sources.n_papers_of_interest\n",
    "    sources[not_surv_label] = sources.n_papers_patented - sources.n_papers_of_interest\n",
    "    sources[err_surv_label] = sources.n_patents_of_interest_error\n",
    "    sources[err_not_surv_label] = sources.n_patents_not_of_interest_error\n",
    "\n",
    "    # Visualize\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=surv_label,\n",
    "            y=sources[source],\n",
    "            x=sources[surv_label],\n",
    "            text='    ' + sources[source].apply(str) + '    ',\n",
    "            orientation='h',\n",
    "            marker_color=color,\n",
    "            base=sources[not_surv_label],\n",
    "        )\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            name=not_surv_label,\n",
    "            y=sources[source],\n",
    "            x=sources[not_surv_label],\n",
    "            orientation='h',\n",
    "            marker_color='darkgrey',\n",
    "            error_x={\n",
    "                'type': 'data',\n",
    "                'array': sources[err_not_surv_label],\n",
    "                'symmetric': True,\n",
    "                'color': error_color,\n",
    "                'thickness': whisk_thick,\n",
    "                'width': whisk_width\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "    if insidetext:\n",
    "        fig.update_traces(\n",
    "            textposition='inside', insidetextanchor=\"end\", insidetextfont=dict(size=13, color='black'),\n",
    "            constraintext='none', cliponaxis=False)\n",
    "    else:\n",
    "        fig.update_traces(textposition='none')\n",
    "    fig.update_traces(marker_line_width = 0)\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(title='Number of papers with downstream patents', title_font_size=20, tickfont_size=15, ticksuffix=' '),\n",
    "        yaxis=dict(title='', dtick=1, tickfont_size=20),\n",
    "        legend=dict(title='', xanchor='center', yanchor='bottom', x=.5, y=1.05, orientation='v', font_size=18),\n",
    "        template='plotly_white', barmode='stack',\n",
    "        title_y=.94, font_size=15, bargap=.12,  paper_bgcolor='rgba(0,0,0,0)', margin=dict(l=0,r=0,t=0,b=0))\n",
    "    fig.update_layout(**kwargs)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dfeb51-6283-417a-ac3e-286a6a112ced",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b10451-162d-4afb-ace6-4b056dddb1b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52769684-9ef1-4693-b2ef-c65d599200ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "papers = filter_paper_years(all_papers, range(1990, 2018))\n",
    "fig = visualize_sources_percents(papers, 'Year', color='mediumvioletred', width=400, height=400, xaxis=dict(range=(1990,2021), dtick=5), condensed_bars=False, error_color='black')\n",
    "plotly.io.write_image(fig, os.path.join(figs_dir, f'years.png'),scale=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317465e-544d-4645-9ea1-58580e513839",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = filter_paper_years(all_papers, range(1990, 2018))\n",
    "fig = visualize_sources_percents(papers, 'Decade', color='mediumvioletred', width=400, height=400,\n",
    "                                 xaxis=dict(tickvals=[1990,2010], ticksuffix='s'), error_color='black')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf233e5-f040-467a-a353-8077f8274b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "papers = filter_paper_years(all_papers, range(1990,2018))\n",
    "fig = visualize_sources_numbers_vertical(\n",
    "    papers, 'Decade', sort=None, stackbars=False, color='mediumslateblue', width=400, height=400, yaxis_range=(0,2010), xaxis_ticksuffix='s', barmode='group', error_color='darkslateblue')\n",
    "plotly.io.write_image(fig, os.path.join(figs_dir, f'decades.png'),scale=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80755095-9206-4daf-b110-25c199b60e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Top words across the decades\n",
    "\n",
    "from fightin_words import bayes_compare_language\n",
    "from collections import Counter\n",
    "\n",
    "# Get decades' paper titles\n",
    "sources = analyze_sources(all_papers, 'Decade')\n",
    "def get_titles(paper_ids):\n",
    "    titles = [all_papers.query(f'PaperId == \"{paper_id}\"').PaperTitle[0] for paper_id in paper_ids]\n",
    "    return titles\n",
    "sources['titles'] = sources.papers.apply(get_titles)\n",
    "\n",
    "# Compute log odds ratios and z-scores\n",
    "l1, l2 = list(sources.titles)\n",
    "fightin_words = bayes_compare_language(l2, l1, ngram=1)\n",
    "words_to_remove = []\n",
    "stopwords = [word.strip() for word in open(os.path.join(data_dir, stopwords_filename)).readlines()]\n",
    "words_to_remove.extend(list(set(stopwords) | {'via', 'using'}))\n",
    "words_to_remove.extend(['network', 'neural', 'networks', 'machine', 'learning', 'models', 'convolutional', 'unsupervised', 'supervised'])\n",
    "fightin_words = list(filter(\n",
    "    lambda word_score: word_score[0] not in words_to_remove, fightin_words))\n",
    "\n",
    "# Visualize top words\n",
    "n = 10\n",
    "top_words = pd.DataFrame(fightin_words[:n] + [('', 0)] + fightin_words[-n:], columns=['word', 'z-score'])\n",
    "fig = px.bar(top_words, x='z-score', y='word', text='word', width=450, height=500, color='z-score',\n",
    "    template='plotly_white', color_discrete_sequence=['midnightblue'], color_continuous_scale='tropic')\n",
    "fig.update_traces(textposition='outside', textfont=dict(size=60), cliponaxis=False,)\n",
    "fig.update_layout(\n",
    "    yaxis_visible=False,\n",
    "    plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)', margin=dict(l=30,r=30,t=0,b=0),\n",
    "    xaxis=dict(dtick=5, title='', range=(-15,15), title_font_color='grey', tickfont_color='grey'), coloraxis_showscale=False\n",
    ")\n",
    "plotly.io.write_image(fig, os.path.join(figs_dir, f'fightin_words.png'),scale=10)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491fac7f-3b59-4af1-840e-9a17972651ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Top entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2158e4a9-a7fc-42dc-8a14-822572634d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_sources_numbers_horizontal(\n",
    "    all_papers, 'Institution', sort='n_papers_of_interest', n=10,  insidetext=False, width=800, color='darkcyan', height=400, xaxis_dtick=100,\n",
    "    error_color='black', whisk_thick=1, yaxis_visible=True, whisk_width=0, font_size=10,\n",
    "    title=dict(text=\"Institutions\".upper(), font=dict(size=17), xanchor='center', x=.5, xref='paper', y=.99),\n",
    "    xaxis=dict(side='top', title_font_size=17, title_standoff=5, tickfont_size=13, range=(0,390)),\n",
    "    yaxis=dict(title='', title_font_size=20, dtick=1, tickfont_size=17, title_standoff=0),\n",
    "    showlegend=False,\n",
    "    legend=dict(xanchor='right', x=.98, yanchor='bottom', y=.1, font_size=20),\n",
    "    yaxis_automargin=False, xaxis_automargin=False, margin=dict(l=300, r=50, t=100, b=50)\n",
    ")\n",
    "plotly.io.write_image(fig, os.path.join(figs_dir, f'top_insts.pdf'), scale=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c9d09f-08bb-468a-8213-045a8a5e6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_sources_numbers_horizontal(\n",
    "    all_papers, 'Country', sort='n_papers_of_interest', n=10,  insidetext=False, width=800, color='darkcyan', height=400, xaxis_dtick=100,\n",
    "    error_color='black', whisk_thick=1, yaxis_visible=True, whisk_width=0, font_size=10,\n",
    "    title=dict(text=\"Nations\".upper(), font=dict(size=17), xanchor='center', x=.5, xref='paper', y=.99),\n",
    "    xaxis=dict(side='top', title_font_size=17, dtick=1000, title_standoff=5, tickfont_size=13, range=(0,3300)),\n",
    "    yaxis=dict(title='', title_font_size=20, dtick=1, tickfont_size=17, title_standoff=0),\n",
    "    showlegend=False,\n",
    "    legend=dict(xanchor='right', x=.98, yanchor='bottom', y=.1, font_size=20),\n",
    "    yaxis_automargin=False, xaxis_automargin=False, margin=dict(l=300, r=50, t=100, b=50)\n",
    ")\n",
    "plotly.io.write_image(fig, os.path.join(figs_dir, f'top_countries.pdf'), scale=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f62da3-da76-4d29-b850-5340a1e0a657",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fieldwide dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8520aa-79a7-4ef6-901d-8bafcc446bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = visualize_sources_percents(\n",
    "    all_papers, 'Institution', filt='n_papers_patented >= 10', color='dimgray', line=True, width=1000, height=400, margin=dict(t=100,b=180),\n",
    "    xaxis=dict(title='', tickangle=270, tickfont_size=6), yaxis_title='Patented papers', condensed_bars=False,\n",
    "    legend=dict(xanchor='left', x=.03, yanchor='bottom', y=1, font_size=15),\n",
    "    background_stack=False, error_color='black')\n",
    "plotly.io.write_image(fig, os.path.join(figs_dir, f'inst_percents_labeled.pdf'),scale=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5310ecf0-3175-4ade-8359-3cc40a7e648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_sources_percents(\n",
    "    all_papers, 'Field', filt='n_papers_patented >= 10', n=150, color='dimgray', line=True, width=1000, height=250, margin=dict(t=0,b=180),\n",
    "    xaxis=dict(title='', tickangle=270, tickfont_size=6), yaxis_title='Patented papers', condensed_bars=False,\n",
    "    legend=dict(xanchor='left', x=.03, yanchor='bottom', y=1, font_size=15), error_color='black', background_stack=False)\n",
    "plotly.io.write_image(fig, os.path.join(figs_dir, f'field_percents_labeled.pdf'),scale=10)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b5cdb6-3847-4891-bb21-fcba4dc7d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = visualize_sources_percents(\n",
    "    all_papers, 'Country', filt='n_papers_patented >= 10', n=150, color='dimgray', line=True, width=400, height=250, margin=dict(t=0,b=0),\n",
    "    xaxis=dict(title='', tickangle=270, tickfont_size=8), yaxis_title='Patented papers',\n",
    "    legend=dict(xanchor='left', x=.03, yanchor='bottom', y=1, font_size=15), error_color='black', background_stack=False)\n",
    "plotly.io.write_image(fig, os.path.join(figs_dir, f'country_percents_labeled.pdf'),scale=10)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whatisai-final",
   "language": "python",
   "name": "whatisai-final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
